% mnras_guide.tex
%
% MNRAS LaTeX user guide
%
% v3.1 released 11 June 2020
%
% v3.0 released 22 May 2015
% (version numbers match those of mnras.cls)
%
% Copyright (C) Royal Astronomical Society 2015
% Authors:
% Keith T. Smith (Royal Astronomical Society)

% Change log
%
% v3.0   September 2013 - May 2015
%    First version: complete rewrite of the user guide
%    Basic structure taken from mnras_template.tex by the same author

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Basic setup. Most papers should leave these options alone.
\documentclass[fleqn,usenatbib,useAMS]{mnras}

%%%%% AUTHORS - PLACE YOUR OWN PACKAGES HERE %%%%%

% Only include extra packages if you really need them. Common packages are:
\usepackage{graphicx}	% Including figure files
\usepackage{amsmath}	% Advanced maths commands
\usepackage{amssymb}	% Extra maths symbols
\usepackage{multicol}        % Multi-column entries in tables
\usepackage{bm}		% Bold maths symbols, including upright Greek
\usepackage{pdflscape}	% Landscape pages

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%% AUTHORS - PLACE YOUR OWN MACROS HERE %%%%%%
\usepackage{subcaption}
% Please keep new commands to a minimum, and use \newcommand not \def to avoid
% overwriting existing commands. Example:
%\newcommand{\pcm}{\,cm$^{-2}$}	% per cm-squared
\newcommand{\kms}{\,km\,s$^{-1}$} % kilometres per second
\newcommand{\bibtex}{\textsc{Bib}\!\TeX} % bibtex. Not quite the correct typesetting, but close enough

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{booktabs}
\usepackage{multirow}




\usepackage[section]{placeins} %ensures figures go in their section e.g https://tex.stackexchange.com/questions/279/how-do-i-ensure-that-figures-appear-in-the-section-theyre-associated-with

% Use vector fonts, so it zooms properly in on-screen viewing software
% Don't change these lines unless you know what you are doing
\usepackage[T1]{fontenc}
\usepackage{ae,aecompl}

% MNRAS is set in Times font. If you don't have this installed (most LaTeX
% installations will be fine) or prefer the old Computer Modern fonts, comment
% out the following line
\usepackage{newtxtext,newtxmath}
% Depending on your LaTeX fonts installation, you might get better results with one of these:
%\usepackage{mathptmx}
%\usepackage{txfonts}

%%%%%%%%%%%%%%%%%%% TITLE PAGE %%%%%%%%%%%%%%%%%%%

% Title of the paper, and the short title which is used in the headers.
% Keep the title short and informative.
	\title[Kalman PTA]{Kalman tracking and estimation of continuous gravitational waves with a pulsar timing array}

% The list of authors, and the short list which is used in the headers.
% If you need two or more lines of authors, add an extra line using \newauthor
\author[Kimpson]{Kimpson$^{1}$, Melatos$^{2}$, O'Leary, Evans$^{3}$, Carlin others, etc. etc.%
\thanks{Contact e-mail: \href{tom.kimpson@unimelb.edu.au}{tom.kimpson@unimelb.edu.au}}%
%\thanks{Present address: Science magazine, AAAS Science International, \mbox{82-88}~Hills Road, Cambridge CB2~1LQ, UK}%
\\
% List of institutions
$^{1}$School of Physics, University of Melbourne, Parkville, VIC 3010, Australia \\
$^{2}$OzGrav, University of Melbourne, Parkville, VIC 3010, Australia \\
$^{3}$Department of Electrical and Electronic Engineering, University of Melbourne, Parkville, Victoria 3010, Australia }

% These dates will be filled out by the publisher
%\date{Last updated 2020 June 10; in original form 2013 September 5}
\date{Last updated \today}

% Enter the current year, for the copyright statements etc.
\pubyear{2023}

% Don't change these lines
\begin{document}
\label{firstpage}
\pagerange{\pageref{firstpage}--\pageref{lastpage}}
\maketitle

% Abstract of the paper
\begin{abstract}	
Continuous nHz gravitational waves from individual supermassive black hole binaries may be detectable with Pulsar Timing Array observations. A novel search strategy is developed wherein intrinsic pulsar timing variations are tracked simultaneously with the modulation induced by a putative gravitational wave. A two-step procedure is applied within a state-space framework, where the model parameters are estimated with a Kalman filter, which provides a likelihood for nested sampling. This enables self-consistent inference of model parameters and calculation of the Bayesian evidence. It is shown via an astrophysically representative software injection campaign that the procedure can distinguish a gravitational wave from pure noise down to a strain of $h_0 \sim 4 \times 10^{-15}$, given an inclination angle $\iota = 1.0$ rad. Full posterior distributions of model parameters are recovered. There is a bias in the estimates of some parameters, introduced by dropping the so-called `pulsar terms', which is analysed and discussed.
\end{abstract}

% Select between one and six entries from the list of approved keywords.
% Don't make up new ones.
\begin{keywords}
gravitational waves -- methods: data analysis -- pulsars: general
\end{keywords}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%% BODY OF PAPER %%%%%%%%%%%%%%%%%%

% The MNRAS class isn't designed to include a table of contents, but for this document one is useful.
% I therefore have to do some kludging to make it work without masses of blank space.
\begingroup
\let\clearpage\relax
%\tableofcontents
\endgroup
\newpage
\section{Introduction}\label{sec:intro}
The inspiral of supermassive black hole binaries \citep[SMBHBs;][]{Rajagopal1995,Jaffe_2003, Wyithe2003,Sesana2013,McWilliams_2014,Ravi2015MNRAS.447.2772R,Burke2019, Skyes2022} is predicted to emit nHz gravitational waves (GWs). Other GW sources in this low-frequency regime include cosmic strings \citep[e.g.][]{PTAstring} and cosmological phase transitions \citep[e.g.][]{PTAphase}. The detection of nHz GWs has necessitated the development of new observational methods, since it is practically impossible to engineer interferometric detectors with sufficiently long baselines. The foremost method is timing an ensemble of pulsars; a pulsar timing array \citep[PTA;][]{ Tiburzi2018, 2021hgwa.bookE...4V}. A nHz GW influences the trajectory and frequency of radio pulses, leaving a characteristic impression on the pulse times of arrival (TOAs) measured at the  Earth. By measuring TOAs from multiple pulsars simultaneously one can effectively construct a detector with a baseline on the scale of parsecs. Multiple PTA detectors have been built over the last few decades, including the North American Nanohertz Observatory for Gravitational Waves \citep[NANOGrav,][]{NANOgrav2023}, the Parkes Pulsar Timing array \citep[PPTA,][]{Parkes2023}, and the European Pulsar Timing Array \citep[EPTA,][]{EPTA2023}. These individual efforts have joined in international collaboration, under the umbrella of the International Pulsar Timing Array \citep[IPTA,][]{2019MNRAS.490.4666P}, along with a number of newer PTAs such as the Indian Pulsar Timing Array Project \citep[InPTA,][]{ipta}, MeerTime \citep{meertime2,Meertime} and the Chinese PTA \citep[CPTA,][]{Hobbs_2019}. \newline 

The incoherent superposition of multiple SMBHB sources leads to a stochastic GW background detectable at nHz frequencies \citep{Allen1997,Sesana10,Christensen2019,Renzini2022}. Previous efforts have mainly focused on detecting the stochastic background by measuring the cross-correlation between the pulsar timing residuals between pairs of pulsars as a function of the angular separation between the pulsars -- the Hellings-Downs curve \citep{Hellings}. After multiple non-detections \citep{Lentati2015,NanoGrav2018,2022MNRAS.510.4873A} consilient evidence for the GW background was presented by NANOGrav \citep{2023ApJ...951L...8A}, EPTA/InPTA \citep{2023arXiv230616214A}, PPTA \citep{2023ApJ...951L...6R} and the CPTA \citep{2023RAA....23g5024X}. \newline 


Individual SMBHBs that are sufficiently massive and nearby may be resolvable with PTAs, allowing the very earliest stages of their evolution and coalescence to be investigated \citep{Sesana2010,Yardley2010,Zhu10,Babak2012,2013CQGra..30v4004E,Zhupulsarterms}. 
Indeed, the stochastic GW background itself may be dominated by a few individual binary sources \citep{Ravi2012singlesource}. Individual SMBHBs are continuous wave sources: they generate persistent, quasi-monochromatic modulations of a known form in pulsar timing residuals. Consequently, they are detected more efficiently by either a frequentist matched filter e.g.\ the ${\cal F}$-statistic \citep{Lee2011MNRAS.414.3251L, Ellis2012ApJ,Zhu2014PPTA} or else Bayesian inference \citep{Ellis2016,Arzoumanian2020A} rather than by cross-correlating pulsar pairs. However, PTA observational efforts to detect individual sources have thus far been unsuccessful \citep{Jenet2004,Zhu2014PPTA,Babak2016,Arzoumanian2023}, with inconclusive evidence at low significance presented by the EPTA for a individual source at 4-5 nHz \citep{2023arXiv230616226A}. \newline 


Intrinsic pulsar timing noise -- i.e.  random, unmodelled, red-spectrum TOA fluctuations due to irregularities in the rotation of the star -- has been identified as a key factor limiting the sensitivity of PTAs to GW signals \citep{Shannon2010,Lasky2015,Caballero2016,Goncharov2021}. This timing noise has multiple theorized causes including free precession \citep{free_precession_kerr,stairs_freeprecession}, microglitches \citep{Alessandro1995,Melatos2008,Espinoza2021}, asteroid encounters \citep{Shannon_2013,Brook_2014}, glitch recovery \citep{Johnston10,Hobbs2010glitch}, fluctuations in internal and external stochastic torques \citep{Cordes1981, 2006MNRAS.370L..76U,Antonelli2023}, variations in the coupling between the stellar crust and core \citep{Jones1990MNRAS.246..364J,Meyers2021,Melatos2023}, magnetospheric state switching \citep{magneto1,Lyne2010L,Stairs2019MNRAS.485.3230S} and superfluid turbulence \citep{Greenstein1970,Peralta2006,Melatos2014}. In order to mitigate the impact of timing noise, PTAs are typically composed of millisecond pulsars (MSPs) which are relatively stable rotators. However, timing noise in MSPs may be a latent phenomenon that will increasingly assert itself as longer stretches of more sensitive data are analysed in the quest to detect nHz GWs \citep{Shannon2010}. In modern Bayesian PTA searches, the power spectral density of the intrinsic timing noise is modeled (usually as a broken or unbroken power law) and estimated, in an effort to distinguish it from the red noise induced by a stochastic GW background (whose spectrum is also red). In addition to the red timing noise there are also secondary, white noise sources that must be considered such as phase jitter noise and radiometer noise \citep{Cordes2010,Lam2019,Parthasarathy2021}. \newline 

In this work we present an alternative and complementary approach to PTA data analysis for individual, quasi-monochromatic, SMBHB sources which self-consistently tracks the intrinsic timing noise in PTA pulsars and disentangles it from GW-induced TOA modulations. The new approach differs from existing approaches in one key respect: it infers the GW parameters conditional on the unique, time-ordered realization of the noisy TOAs observed, instead of fitting for the ensemble-averaged statistics of the TOA noise process, e.g., the amplitude and exponent of its power spectral density. Stated another way, existing approaches seek to detect a GW signal by marginalizing over the ensemble of possible noise realizations, whereas the new approach delivers the most likely set of GW parameters consistent with the actual, observed noise realization. The new and existing approach are therefore complementary, but the new approach holds out the promise of somewhat higher sensitivity. In particular, we formulate PTA analysis as a state-space problem and demonstrate how to optimally estimate the state-space evolution using a Kalman filter, a tried-and-tested tool \citep{Kalman1,Meyers2021,Melatos2023}. We combine the Kalman tracking of the pulsars intrinsic rotational state with a Bayesian nested sampler \citep{Skilling, Ashton2022} to estimate the GW parameters and calculate the marginal likelihood for model selection. \newline 

% --- a promise which we aim to test as the key goal of this paper. 
\noindent This paper is organised as follows. In Section \ref{sec:model} we present the state-space model for the pulsar frequency which is subject to the influence of a GW. In Section \ref{sec:detect} we develop a Kalman filter to track the state evolution and introduce how to deploy the Kalman filter in conjunction with nested sampling to estimate the system parameters and the model evidence. In Section \ref{sec:testing} we test this new method on synthetic pulsar data. Throughout this work we adopt the natural units, with $c = G = \hbar = 1$, and a $(-,+,+,+)$ metric signature. \newline 




%
%The detection of high frequency ($\sim 100$ Hz) gravitational waves (GWs) from coalescing black hole (BH) binaries with ground-based detectors such as LIGO/Virgo \citep{aLIGO,2015CQGra..32b4001A} is now a routine enterprise \citep[e.g.][]{2019PhRvX...9c1040A,2021PhRvX..11b1053A}. GWs from sources which radiate in the mill-Hz regime are expected to be detectable from $\sim 2037$ with the space-based Laser Interferometer Space Antenna, \citep{LISApaper}, especially given the early success by the pathfinder mission \citep{2019arXiv190308924A}.

%
% Detecting GWs from systems which evolve over even longer timescales, $\mathcal{O}$(years), 
%



\section{State-Space Formulation}\label{sec:model}
We formulate the PTA analysis as a state-space problem, in which the intrinsic rotational state of each pulsar evolves according to a stochastic differential equation and is related to the observed pulse sequence via a measurement equation. In this work we take the intrinsic state variable to be the pulsar's spin frequency $f_{\rm p}^{(n)}(t)$, as measured in the local rest frame of the pulsar's centre of mass. A model for the evolution of $f_{\rm p}^{(n)}(t)$ is presented in Section \ref{sec:psr_frequency}.  We take the measurement variable to be the radio pulse frequency measured by an observer at Earth, $f_{\rm m}^{(n)}(t)$.  The measurement equation relating $f_{\rm m}^{(n)}(t)$ to $f_{\rm p}^{(n)}(t)$ is presented in Section \ref{sec:psr_measured}. The superscript $1\leq n\leq N$ indexes the $n$-th pulsar in the array.
\subsection{Spin evolution} \label{sec:psr_frequency}
A predictive, first-principles theory of timing noise does not exist at present; there are several plausible physical mechanisms, referenced in Section \ref{sec:intro}. We therefore rely on an idealized phenomenological model to capture the main qualitative features of a typical PTA pulsar's observed spin evolution, i.e.\ random, small-amplitude excursions around a smooth, secular trend. In the model, $f_{\rm p}^{(n)}(t)$ evolves according to the sum of a deterministic torque and a stochastic torque. The deterministic torque is attributed to magnetic dipole braking, with braking index $n_{\rm em}=3$. Most PTAs involve millisecond pulsars, for which the quadratic correction due to $n_{\rm em}$ in $f_{\rm p}^{(n)}(t)$ is negligible over the observation time $T_{\rm obs} \sim 10 \, {\rm yr}$, and the deterministic evolution $f_{\rm em}^{(n)}(t)$ can be approximated accurately by 
\begin{equation}
 f_{\rm em}^{(n)}(t) = f_{\rm em}^{(n)}(t_1) + \dot{f}_{\rm em}^{(n)}(t_1)t \ , \label{eq:spinevol}
\end{equation} where an overdot denotes a derivative with respect to $t$ and $t_1$ labels the time of the first TOA. The stochastic torque is assumed to be a zero-mean, white noise process. Specifically, the frequency evolves according to an Ornstein-Uhlenbeck process, described by a Langevin equation with a time-dependent drift term \citep{Vargas}
\begin{equation}
	\frac{df_{\rm p}^{(n)}}{dt} = -\gamma^{(n)}	 [f_{\rm p}^{(n)} - f_{\rm em}^{(n)} (t)] + \dot{f}_{\rm em}^{(n)} +\xi^{(n)}(t) \ . 
	\label{eq:frequency_evolution}
\end{equation}
In Equation \eqref{eq:frequency_evolution}, $f_{\rm em}$ is the solution of the electromagnetic spindown equation, $\dot{f}_{\rm em}$ is the spin derivative, $\gamma^{(n)}$ a damping constant whose reciprocal specifies the mean-reversion timescale, and $\xi^{(n)}(t)$ satisfies:
\begin{align}
	\langle \xi^{(n)}(t) \rangle &= 0 \ , \\
	\langle \xi^{(n)}(t) \xi^{(n)}(t') \rangle &= [\sigma^{(n)}]^2 \delta(t - t') \ .	\label{eq:xieqn}
\end{align}
$[\sigma^{(n)}]^2$ is the variance of $\xi^{(n)}$ and parametrizes the amplitude of the noise, and combined with the mean reversion it gives a characteristic root mean square fluctuations $\approx [\sigma^{(n)}]^2 / \gamma^{(n)}$ in $f_{\rm p}^{(n)}(t)$ \citep{gardiner2009stochastic}. It is important to note that the white noise fluctuations in $\xi(t)$ translate into red noise fluctuations in the rotational phase $\phi(t) = \int_{t_1}^t dt' \, f_{\rm p}(t')$ after being filtered by the terms involving $d/dt$ and $\gamma$ in Equation \eqref{eq:spinevol}, consistent with the observed power spectral density of typical millisecond pulsars in the nHz band relevant to PTA experiments. \newline 


Equations \eqref{eq:spinevol}--\eqref{eq:xieqn} represent a phenomenological model, which aims to reproduce qualitatively the typical timing behaviour observed in PTAs, viz.\ a mean-reverting random walk about a secular spin-down trend \citep{NANOgrav2023,EPTA2023,Zic2023arXiv230616230Z}. Equations \eqref{eq:spinevol}--\eqref{eq:xieqn} are not derived from first principles by applying a microphysical theory. As a first pass, they also exclude certain phenomenological elements, which are likely to be present in reality, e.g.\ the classic, two-component, crust-superfluid structure inferred from post-glitch recoveries \citep{Baym1969,vanEysden,Alpar2017MNRAS.471.4827G}. An approach akin to Equations \eqref{eq:spinevol}--\eqref{eq:xieqn} has been followed successfully in other timing analyses in the context of anomalous braking indices \citep{Vargas} and hidden Markov model glitch searches \citep{Melatos2020ApJ...896...78M,Lower2021MNRAS.508.3251L,Dunn2022,Dunn2023MNRAS.522.5469D}. However, Equations \eqref{eq:spinevol}--\eqref{eq:xieqn}  involve significant idealizations, which must be recognized at the outset \citep{Meyers2021,Myers2021MNRAS.502.3113M,Vargas}. First, the white noise driver $\xi(t)$ in Equation \eqref{eq:frequency_evolution} is not differentiable, which makes the formal interpretation of $d^2 f_{\rm p} / dt^2$ ambiguous, even though $d^2 f_{\rm p} / dt^2$ is not used in the PTA analysis proposed in this paper. Second, the white spectrum assumed for $\xi(t)$ may or may not be suitable for millisecond pulsars in PTAs. It is challenging observationally to infer the spectrum of $\xi(t)$ from the observed spectrum of the phase residuals, because the inference is conditional on the (unknown) dynamical model governing $df_{\rm p}/dt$. For small-amplitude fluctuations sampled relatively often, as in millisecond pulsars in PTAs, it is likely that $\xi(t)$ is white to a good approximation over the inter-TOA intervals and generates red phase residuals as observed, but caution is warranted nevertheless. Third, the Brownian increment $dB(t)=\xi(t)dt$ does not include non-Gaussian excursions such as L\'{e}vy flights \citep{Sornette2004} which have not been ruled out by pulsar timing experiments to date. The above three idealizations are supplemented by other, physical approximations noted above, e.g.\ neglecting $n_{\rm em}$ in Equation \eqref{eq:spinevol} and differential rotation between the crust and superfluid in Equation \eqref{eq:frequency_evolution}.



\subsection{Modulation of pulsar frequency by a GW} \label{sec:psr_measured}
In the presence of a GW, the pulsar frequency measured by an observer in the local rest frame of the neutron star's center of mass is different from that measured by an observer on Earth. Specifically, the pulsar frequency is modulated harmonically at the GW frequency. We derive the nonlinear measurement equation relating $f_{\rm m}(t)$ to $f_{\rm p}(t)$ in this section. The measurement equation is a key input into the Kalman filter in Section \eqref{sec:kalman_filter}
\subsubsection{Plane GW perturbation}\label{sec:plane_gw}
We consider a gravitational plane wave from a single,distant source, which perturbs a background Minkowski metric $\eta_{\mu \nu}$ as
\begin{equation}
	g_{\mu \nu} = \eta_{\mu \nu} + H_{\mu \nu} \exp{ \{ i[\Omega(\boldsymbol{n} \cdot \boldsymbol{x} - t) + \Phi_0] \} } \ ,
\end{equation}
with spatial coordinates $\boldsymbol{x}$ and global coordinate time $t$. The GW has a constant angular frequency $\Omega$, propagates in the $\boldsymbol{n}$-direction (where $\boldsymbol{n}$ is a unit vector), has amplitude tensor $H_{\mu \nu}$, and has a phase offset  $\Phi_0$. Throughout this paper we work with pulsar TOAs which have been defined relative to the Solar System barycentre (SSB). We are free to choose our coordinate system such that $\Phi_0$ is the GW phase at $t=0$ at the SSB. In this paper $\Omega$ has no time dependence; the source is approximated as monochromatic. Studies of SMBHB inspirals in the PTA context show that the gravitational wave frequency $f_{\rm gw}$ ($=\Omega / 2 \pi $) evolves over decadal timescales as \citep[e.g.][]{Zhu10},
\begin{equation}
	\Delta f_{\rm gw} \simeq 3.94 \mathrm{nHz}\left(\frac{M_c}{10^9 M_{\odot}}\right)^{5 / 3}\left(\frac{f_{\rm gw}(t=0)}{10^{-7} \mathrm{~Hz}}\right)^{11 / 3}\left(\frac{T_{\mathrm{obs}}}{10 \mathrm{yr}}\right) \ ,
	\label{eq:f_evolution}
\end{equation}
where $M_c$ is the chirp mass of the SMBHB, $f_{gw}(t=0)$ is the GW frequency at the time of the first observation, and $T_{\rm obs}$ the length of the data timespan, which for PTAs is $\sim 10$ years. A source can be considered as monochromatic if $\Delta f_{\rm gw}$ is less than the PTA frequency resolution of $1/T_{\rm obs}$. From Equation \eqref{eq:f_evolution} we can see that only those binaries which are very massive or at very high frequency experience significant frequency evolution over typical PTA timespans. The majority of SMBHBs detectable with PTAs are expected to satisfy $\Delta f_{\rm gw} < 1/T_{\rm obs}$; for a PTA with pulsars at 1.5 kpc, 78 \% of simulated SMBHBs satisfy this condition for the current IPTA, whilst for the second phase of the Square Kilometer Array this fraction drops to 52 \%; see Figure 7 in  \cite{Rosado10.1093/mnras/stv1098}. We are therefore justified in treating the GW source as monochromatic \citep{Sesana10,Sesana2010,Ellis2012ApJ}. \newline 


The amplitude tensor $H_{\mu \nu}$ has zero temporal components ($H_{0 \mu} = H_{\mu 0} = 0$). The spatial part is
\begin{align}
	H_{ij} = h_+ e_{ij}^+(\boldsymbol{n}) + h_{\times} e_{ij}^{\times}(\boldsymbol{n}) \ , \label{eq:hij}
\end{align}
where $h_{+}$ and $h_{\times}$ are the respective polarisation amplitudes. The plus and cross polarisation tensors $e_{ij}^{+}$ and $e_{ij}^{\times}$ are uniquely defined by the principal axes of the wave, viz.\ the unit 3-vectors $\boldsymbol{k}$ and $\boldsymbol{l}$, according to
\begin{align}
	e_{i j}^{+}(\boldsymbol{n}) =k_i k_j-l_i l_j \ , \\
		e_{i j}^{\times}(\boldsymbol{n}) =k_i l_j+l_i k_j \ .
\end{align}
The principal axes are in turn specified by the location of the GW source on the sky (via colatitude $\theta$ and azimuth $\phi$) and the polarisation angle $\psi$ according to
\begin{align}
	\boldsymbol{k}  = &(\sin \phi \cos \psi-\sin \psi \cos \phi \cos \theta) \boldsymbol{\hat{x}} \nonumber \\
	& -(\cos \phi \cos \psi+\sin \psi \sin \phi \cos \theta) \boldsymbol{\hat{y}} \nonumber \\
	& +(\sin \psi \sin \theta) \boldsymbol{\hat{z}} \ , \\
	\boldsymbol{l} = &(-\sin \phi \sin \psi-\cos \psi \cos \phi \cos \theta) \boldsymbol{\hat{x}} \nonumber \\
	& +(\cos \phi \sin \psi-\cos \psi \sin \phi \cos \theta) \boldsymbol{\hat{y}}\nonumber  \\
	& +(\cos \psi \sin \theta) \boldsymbol{\hat{z}} \ ,
\end{align}
where e.g. $\boldsymbol{\hat{x}}$ is a unit vector in the direction of the $x$-axis. The direction of GW propagation is related to the principal axes by
\begin{equation}
	\boldsymbol{n} = \boldsymbol{k} \times \boldsymbol{l} \ . 
\end{equation}




\subsubsection{Measurement equation}
In general radio pulses from a pulsar are transmitted as amplitude modulations of a radio-frequency carrier wave. They are described by the geometric object $\vec{p}$ which we can identify  as the 4-momentum of the radio photon. The presence of a GW induces a shift in the temporal component of the covariant 4-momentum between the emitter and the observer, i.e. $\Delta p_t = p_t|_{\rm observer} - p_t|_{\rm emitter} $, as \citep[e.g.][]{Maggiore}
\begin{equation}
 \Delta p_t = \frac{\omega}{2} \frac{ h_{ij} (t; \boldsymbol{x}= 0)q^i q^j }{(1 + \boldsymbol{n}\cdot \boldsymbol{q}) }  \left(1 -e^{i \Omega (1 + \boldsymbol{n}\cdot \boldsymbol{q})  d}\right)
	\label{eq:momentum_shift}
\end{equation}
where $\omega$ is the angular pulse frequency $(= 2 \pi f_{\rm p})$ measured in the momentarily comoving reference frame of an observer, $h_{ij} = g_{ij} - \eta_{ij}$, $\boldsymbol{q}$ is the unit vector connecting the observer and the pulsar and $d$ is the distance to the pulsar. We take the pulsar location to be constant i.e.  neither $\boldsymbol{q}$ nor $d$ is a function of time. In practice the pulsar locations vary with respect to the Earth but are constant with respect to the SSB. This barycentering correction is typically applied when generating TOAs using e.g. {\sc tempo2} \citep{tempo2} and related timing software. Generally the measured frequency of a photon recorded by an observer who is travelling with 4-velocity $\boldsymbol{u}$ is given by the coordinate-independent expression:
\begin{equation}
	f = p_{\alpha} u^{\alpha} \ . 
	\label{eq:freq_temporal}
\end{equation}
Due to the kinematical corrections from the barycentering process, 
\begin{equation}
	u^{\alpha}|_{\rm emitter} = u^{\alpha}|_{\rm receiver} = (1,0,0,0) \ ,
\end{equation}
where the perturbations to $\boldsymbol{u}$ from the GW are of higher order and neglected. In this case the shift in the momentum from Equation \eqref{eq:momentum_shift} can be related to a shift in the frequency as,
\begin{equation}
	f_{\rm m}^{(n)}(t) = f_{\rm p}^{(n)}(t-d) g^{(n)}(t) \ ,
	\label{eq:measurement}
\end{equation}
where
\begin{equation}
	g^{(n)}(t) = 1 -  \frac{1}{2} \frac{h_{ij} (t; \boldsymbol{x}= 0)q^{i,(n)} q^{j,(n)}}{(1 + \boldsymbol{n}\cdot \boldsymbol{q}^{(n)}) }  \left(1 -e^{i \Omega \left[1 + \boldsymbol{n}\cdot \boldsymbol{q}^{(n)} \right]  d^{(n)}}\right) \ .
	\label{eq:g_func}
\end{equation}
and $q^{i,(n)}$ labels the $i$-th coordinate component of the of the $n$-th pulsars position vector $\boldsymbol{q}^{(n)}$. It is also instructive to express Equation \eqref{eq:g_func} in a trigonometric form as,
\begin{align}
	g^{(n)}(t) &= 1 - \frac{1}{2} \frac{ H_{ij}q^{i,(n)} q^{j,(n)} }{(1 + \boldsymbol{n}\cdot \boldsymbol{q}^{(n)}) } \nonumber \\
	& \times \Big\{ \cos\left[-\Omega t +\Phi_0\right] \nonumber \\
	&- \cos \left[-\Omega t +\Phi_0 + \Omega \left(1 + \boldsymbol{n}\cdot \boldsymbol{q}^{(n)} \right)  d^{(n)} \right] \Big\} \ .
	\label{eq:g_func_trig}
\end{align}
Equations \eqref{eq:measurement} -- \eqref{eq:g_func_trig},  define a measurement equation that relates the intrinsic pulsar spin frequency to the frequency measured by an observer on Earth. 

\section{Signal tracking, parameter estimation and model selection} \label{sec:detect}
The set of static parameters $\boldsymbol{\theta}$ of the model outlined in Section \ref{sec:model} can be separated into parameters which correspond to the intrinsic frequency evolution of the pulsar, and parameters of the GW source, i.e. 
\begin{equation}
	\boldsymbol{\theta} =  \boldsymbol{\theta}_{\rm psr} \cup \boldsymbol{\theta}_{\rm gw} \ , \label{eq:params1}
\end{equation}
with
\begin{equation}
	\boldsymbol{\theta}_{\rm psr} = \left \{ \gamma^{(n)}, f_{\rm em}^{(n)}(t_1),\dot{f}_{\rm em}^{(n)}(t_1),d^{(n)},\sigma^{(n)}\right\}_{1\leq n \leq N} \ , \label{eq:psrparams}
\end{equation}
and
\begin{equation}
	\boldsymbol{\theta}_{\rm gw} = \left \{h_0, \iota, \delta, \alpha, \psi, \Omega, \Phi_0 \right \} \ .  \label{eq:params3}
\end{equation}
where $\delta$ is the declination of the GW source and $\alpha$ the right ascension. In Equation \eqref{eq:params3} we have reparameterized the two GW polarisation strains, $h_{+}, h_{\times}$, in terms of the GW amplitude $h_0$ and the system inclination $\iota$:
\begin{align}
	h_+ &= h_0(1 + \cos^2 \iota) 	\label{eq:hphx} \ ,\\
	h_{\times} &= -2h_0\cos \iota 	\label{eq:hphx2} \ , 
\end{align}
where $\iota$ is the angle between the normal to the SMBHB orbital plane, $\boldsymbol{L}$, and the observer line of sight, i.e. $\cos \iota = \boldsymbol{n} \cdot \boldsymbol{L}$. We use this parametrisation in terms of $h_0$ and $\iota$ throughout the remainder of this work. For a PTA dataset containing $N$ pulsars we then have $7 + 5N$ parameters to estimate. Typically the pulsar parameters are better constrained than the GW parameters; for example estimates of pulsar distances are accurate to $\sim$ 10$\%$ \citep{Cordes2002astro.ph..7156C, Verbiest2012ApJ...755...39V, Desvignes2016,Yao2017}, but we have no prior information on the SMBHB GW source location.  \newline 

In this section we present a new method to infer $\boldsymbol{\theta}$ and calculate the marginal likelihood (i.e. the model evidence). In Section \ref{sec:kalman_filter} we outline how noisy measurements of the pulsar frequency, $f_{\rm m}^{(n)}(t)$, can be used to estimate the hidden state sequence, $f_{\rm p}^{(n)}(t)$, using a Kalman filter. In Section \ref{sec:nested_sampling} we demonstrate how to deploy the Kalman filter in conjunction with a nested sampling technique to perform Bayesian inference of the model parameters and calculate the model evidence. Model selection and the specification of the null model is described in Section \ref{sec:model_selection}. A complete summary of the method is presented in Section \ref{sec:methodsummary}.

\subsection{Kalman filter}\label{sec:kalman_filter}









%
%\begin{figure*}
%	\centering
%	
%	\subfloat[a]{\includegraphics[width=0.5\textwidth]{images/Kalman_example_both}} 
%	\subfloat[b]{\includegraphics[width=0.3\textwidth]{images/Kalman_example_both}}
%	\caption{\textcolor{red}{TK: For consideration. Do we prefer this figure to Figure \ref{fig:four figures}}?}
%	\label{fig:kalmanexampleboth}
%\end{figure*}
%


\begin{figure*}
	%\centering % Not needed
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{images/Kalman_example_true_params_single}
		\caption{Kalman filter using correct estimate of the static parameters, $\hat{\boldsymbol{\theta}} = \boldsymbol{\theta}$ }
		\label{fig:6MB_BFS}
	\end{subfigure}  
    \hfill
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{images/Kalman_example_wrong_params}
		\caption{Kalman filter using incorrect estimate of the static parameters, $\hat{\boldsymbol{\theta}} \neq \boldsymbol{\theta}$}
		\label{fig:25MB_bfs}
	\end{subfigure}
	\caption{Example application of a Kalman filter to estimate the intrinsic pulsar frequency state $f_{\rm p}(t)$ given a measured frequency $f_{\rm m}(t)$. We plot the ephemeris subtracted state $f'_{\rm p}(t) = f_{\rm p}(t) - f_{\rm em} (t)$ to better illustrate the stochastic wandering of the pulsar frequency. In (a) the Kalman filter is run using identically correct estimates of the static system parameters, $\hat{\boldsymbol{\theta}} = \boldsymbol{\theta}$ and the state is estimated accurately. In (b) the Kalman filter is run with $\hat{\boldsymbol{\theta}} \neq \boldsymbol{\theta}$ and the state is not estimated accurately. The top panels show the true pulsar state $f'_{\rm p}(t)$ (blue line) and the state estimated by the Kalman filter, $\hat{f'}_{\rm p}(t)$ (green line). The middle panels show the true $f_{\rm m}(t)$ (red line) and the measured frequency estimated  by the Kalman filter, $\hat{f}_{\rm m}(t)$ (magenta). The bottom panels show the residual or the innovation $\epsilon(t) =f_{\rm m}(t) - \hat{f}_{\rm m}(t)$. In (a) the green/blue and red/magenta lines are completely overlaid.}
	\label{fig:four figures}
\end{figure*}

The Kalman filter \citep{Kalman1} is a Gaussian-Markov model used to algorithmically recover the most likely set of unknown system state variables, $\boldsymbol{X}$, given some noisy measurements, $\boldsymbol{Y}$. It is a common technique in signal processing that has been applied successfully in neutron star astrophysics \citep[e.g.][]{Meyers2021,Melatos2023}. In this work we use the linear Kalman filter which assumes a linear relation between $\boldsymbol{X}$ and $\boldsymbol{Y}$. Whilst the measurement equation, Equation \eqref{eq:measurement}, is non-linear in the static parameters it is linear in the state and measurement variables, $f_{\rm p}^{(n)}$ and $f_{\rm m}^{(n)}$ respectively. Extension to non-linear problems is straightforward using either an extended Kalman filter \citep{zarchan2000fundamentals}, the unscented Kalman filter \citep{882463van} or the particle filter \citep{Simon10}. \newline 


The full set of Kalman recursions is presented in Appendix \ref{sec:kalman}. At each discrete timestep indexed by $ 1 \leq i  \leq M$, the Kalman filter returns an estimate of the state variables, $\hat{\boldsymbol{X}}_i$, and the covariance of those estimates, $\boldsymbol{P}_i$. The filter tracks the error in its predictions of $\boldsymbol{X}_i$ by projecting the state predictions back into measurement space, $\hat{\boldsymbol{X}}_i \mapsto \hat{\boldsymbol{Y}}_i$, via the measurement equation, Equation \eqref{eq:measurement}. The measurement predictions can then be compared against the true observed noisy measurements to get a residual $\boldsymbol{\epsilon}_i = \boldsymbol{Y}_i  - \hat{\boldsymbol{Y}}_i$, sometimes termed the ``innovation". The Kalman filter also calculates the uncertainty in $\boldsymbol{\epsilon}_i$ via the innovation covariance $\boldsymbol{S}_i = \langle \boldsymbol{\epsilon}_i \boldsymbol{\epsilon}_i^{\intercal} \rangle$. The Gaussian log-likelihood can then be calculated at each timestep:
\begin{eqnarray}
	\log \mathcal{L}_i =  -\frac{1}{2} \left (N \log 2 \pi + \log  \left | \boldsymbol{S}_i \right | + \boldsymbol{\epsilon}_i^{\intercal} \boldsymbol{S}_i^{-1}  \boldsymbol{\epsilon}_i \right ) \ ,
\end{eqnarray}
with the total log-likelihood simply the sum over all timesteps, i.e. 
\begin{eqnarray}
	\log \mathcal{L} =  \sum_{i=1}^{i=M} \log \mathcal{L}_i \ . \label{eq:likelihood}
\end{eqnarray}
For fixed data $\boldsymbol{Y}$, $\mathcal{L}$ is a function of the static parameters of the model, i.e. $\mathcal{L}$ = $\mathcal{L}(\boldsymbol{Y} | \boldsymbol{\theta})$. Similarly the estimates of the state and measurement variables, $\hat{\boldsymbol{X}}$ and $\hat{\boldsymbol{Y}}$, are also functions of $\boldsymbol{\theta}$. If the estimates of the system parameters, $\boldsymbol{\hat{\theta}}$ , that we pass to the Kalman filter are close to the true underlying parameters then the errors in $\hat{\boldsymbol{X}}$ and $\hat{\boldsymbol{Y}}$ are	 minimized and $\mathcal{L}$ is maximised. This is illustrated in Figure \ref{fig:6MB_BFS}; given a timeseries of the measured pulsar frequency the Kalman filter is able to recover the evolution of the hidden state with high fidelity. The residuals correspond to random noise and are normally distributed. Conversely, if $\boldsymbol{\hat{\theta}}$ is not close to the true parameters then the filter is unable to recover the state evolution. This is demonstrated in Figure \ref{fig:25MB_bfs} where the Kalman filter was run with $\boldsymbol{\hat{\theta}}$ slightly perturbed away from the true values. In this case the filter cannot track the state variable accurately and the residuals are no longer Gaussian.


\subsection{Nested Sampling}\label{sec:nested_sampling}
We can use the likelihood returned by the Kalman filter, Equation \eqref{eq:likelihood}, in conjunction with likelihood-based inference methods to estimate the posterior distribution of $\boldsymbol{\theta}$ by Bayes' Rule,
\begin{equation}
	p(\boldsymbol{\theta} | \boldsymbol{Y}) = \frac{\mathcal{L}(\boldsymbol{Y} | \boldsymbol{\theta}) \cdot \pi(\boldsymbol{\theta})}{\mathcal{Z}} \ ,
\end{equation}
where $\pi(\boldsymbol{\theta})$ is the prior distribution on $\boldsymbol{\theta}$ and $\mathcal{Z}$ is the marginalised likelihood, or evidence
\begin{equation}
	\mathcal{Z} = \int d \boldsymbol{\theta} \mathcal{L}(\boldsymbol{Y} | \boldsymbol{\theta})  \pi(\boldsymbol{\theta})  \ . \label{eq:model_evidence}
\end{equation}
In order to estimate the posterior distribution and the model evidence we use nested sampling \citep{Skilling} throughout this work. Nested sampling is an integration algorithm used for evaluating marginalised likelihood integrals, of the form given by Equation \eqref{eq:model_evidence}, that also returns samples from the posterior, $p(\boldsymbol{\theta} | \boldsymbol{Y})$. It does this by drawing a set of $n_{\rm live}$ live points from $\pi(\boldsymbol{\theta})$ and then iteratively replacing the live point with the lowest likelihood with a new live point drawn from $\pi(\boldsymbol{\theta})$, where the new live point is required to have a higher likelihood than the discarded point. The primary advantage of nested sampling is the ability to compute the evidence integral, which is key for model selection, and proves difficult without considerable extra cost for the usual Markov Chain Monte Carlo (MCMC) approaches. Nested sampling is also typically less computationally intensive than MCMC and can handle multi-modal problems \citep{Ashton2022}. For these reasons, it has enjoyed widespread adoption in the physical sciences, particularly within the cosmological community \citep{Mukherjee2006,Feroz2008,Handley2015}, but has also commonly been applied in astrophysics \citep{UltraNest2021}, particle physics \citep{proceedings2019033014} and materials science \citep{2009arXiv0906materials}. For a review of nested sampling we refer the reader to \cite{Buchner2021} and \cite{Ashton2022}. Multiple nested sampling algorithms and computational libraries exist. \citep[e.g.][]{Feroz2008,Feroz2009,Handley2015,dynesty2020,UltraNest2021}. For gravitational astrophysics it is common to use the \texttt{dynesty} sampler \citep{dynesty2020} via the \texttt{Bilby} \citep{bilby.507.2037A} front-end library. We  follow this precedent and use \texttt{Bilby} for all nested sampling Bayesian inference in this work. The primary tunable parameter in nested sampling is $n_{\rm live}$, where a greater number of live points is advantageous for large parameter spaces and multi-modal problems, whilst the uncertainties in the evidence and the posterior scale as $\mathcal{O}(1/\sqrt{n_{\rm live}})$. However the computational runtime scales as $\mathcal{O}(n_{\rm live})$ and so one must make a trade-off between uncertainty and runtime. \cite{Ashton2022} offer a rule-of-thumb where the minimum number of live points should be greater than the number of static parameters. The results presented in this work are generally robust to the choice of $n_{\rm live}$, subject to the requirement of $n_{\rm live} > 7 + 5N$. Unless stated otherwise we take $n_{\rm live} = 1000$ for all results presented in this work. \newline 

%See https://arxiv.org/pdf/2102.12478.pdf for a good NS explanation

\subsection{Model selection}\label{sec:model_selection}
The evidence integral $\mathcal{Z}$ returned by nested sampling is the probability of the data $\boldsymbol{Y}$ given a particular model $\mathcal{M}_i$. This enables us to compare competing models via a Bayes factor,
\begin{equation}
	\beta = \frac{\mathcal{Z}(\boldsymbol{Y} | \mathcal{M}_1)}{\mathcal{Z}(\boldsymbol{Y} | \mathcal{M}_0)} \ . \label{eq:bayes}
\end{equation}
Throughout this work we take $\mathcal{M}_1$ to be the state space model that includes the presence of a GW $\mathcal{M}_0$ is our null model that assumes there is no GW in the data. This is equivalent to setting $g^{(n)}(t)=1$ in Equations \eqref{eq:g_func} and \eqref{eq:g_func_trig}. The Bayes factors we quote in this work therefore quantify whether the data supports evidence for a GW compared to there being no GW signal present.


\subsection{Summary of workflow}\label{sec:methodsummary}
To summarise the above, the order of operations in our method for a single iteration (i.e. for a single live point) is as follows:
\begin{enumerate}
	\item Sample from the prior $\pi(\boldsymbol{\theta})$ to obtain $\boldsymbol{\theta}_{\rm sample}$
    \item Pass $\boldsymbol{\theta}_{\rm sample}$ to the Kalman filter.
	\item Iterate over the data $\boldsymbol{Y}$ using the Kalman filter and obtain a single $\log \mathcal{L}$ value
	\item Return $\log \mathcal{L}$ to the nested sampler
    \item Nested sampler updates $p\left(\boldsymbol{\theta}|\boldsymbol{Y}\right)$
\end{enumerate}
In Section \ref{sec:testing} we apply this workflow on a synthetic data set.

\section{Tests with synthetic data} \label{sec:testing}
In this section we use synthetic data to test the ability of our method to detect the presence of a GW in noisy data and recover the static parameters, $\boldsymbol{\theta}$. In Section \ref{sec:synth_data} we discuss how the synthetic data is generated, including the construction of an artificial PTA. In Section \ref{sec:rep_example} we generate synthetic data for a single representative example SMBHB system and apply our method to estimate $\boldsymbol{\theta}$ and calculate the statistical evidence for a GW in the data via the Bayes factor. In this section we also explore how the detectability of the system changes for different strain magnitudes, $h_0$ and the performance of the method for different realisations of the pulsar process noise and the measurement noise. In Section \ref{sec:parameter_space} we move beyond a single example system and test our method across a broader parameter space. In Section \ref{sec:bias} we discuss biases that are evident in some of the parameter estimates.

\subsection{Synthetic data generation} \label{sec:synth_data}

\subsubsection{Constructing a synthetic PTA}\label{sec:synt_pta}

\begin{figure}
	\includegraphics[width=\columnwidth]{images/pulsar_distribution}
	\caption{Spatial distribution of 47 pulsars from the 12.5 year NANOGrav data release that make up the synthetic PTA used in this work. The pulsar distances relative to the observer are also indicated, with the majority of pulsars having a distance $\sim 1$ kpc. The grey dashed line denotes the Galactic plane.}
	\label{fig:pulsar_distrib}
\end{figure}
For this work we generate synthetic data that is astrophysically representative as follows. We first specify a set of pulsars to make up our artificial PTA. We take the 47 pulsars that make up the 12.5 year NANOGrav PTA \citep{2020ApJ...905L..34A}. The NANOGrav pulsars are chosen arbitrarily as being representative of a typical PTA and the method naturally extends to any other PTA. For each pulsar we obtain the sky location (which defines the vector $\boldsymbol{q}^{(n)}$), the distance, the barycentric rotation frequency (which we identify with $f_{\rm em}^{(n)} (t_1)$), and the time derivative of the the barycentric rotation frequency (which we identify with $\dot{f}_{\rm em}^{(n)} (t_1)$). The spatial distribution and the distances of the pulsars used for this artificial PTA are shown in Figure \ref{fig:pulsar_distrib}. The data is acquired via the Australia Telescope National Facility (ATNF) pulsar catalogue \citep{Manchester2005} using the \texttt{psrqpy} package \citep{psrqpy}. The remaining unspecified pulsar parameters are $\gamma^{(n)}$ and $\sigma^{(n)}$. We discussed in Section \ref{sec:psr_frequency} how the quantity $[\sigma^{(n)}]^2 /\gamma^{(n)} $ sets the amplitude of the characteristic root mean square fluctuations in $f_p^{(n)}(t)$. Typically the mean reversion timescale $[\gamma^{(n)}]^{-1} \gg T_{\rm obs}$ \citep{Vargas}, whilst $[\sigma^{(n)}]^2$ varies between individual pulsars. For this work we fix $\gamma^{(n)} = 10^{-13}$ s$^{-1}$ for all $n$. In order to set a physically reasonable value for $[\sigma^{(n)}]^2$ we use two complementary approaches. The first approach uses the empirical timing noise model from \cite{Shannon2010ApJ...725.1607S} where the standard deviation in the pulsar TOA is given by:
\begin{align}
	\ln \left(\frac{\sigma_{\rm TOA}^{(n)}}{\mu s} \right)&= \ln \alpha_1 +  \alpha_2 \ln f_{\rm p}^{(n)} + \alpha_3 \ln \left(\frac{\dot{f}_{\rm p}^{(n)}}{10^{-15} \text{s}^{-2}} \right) \nonumber \\ 
	&+ \alpha_4 \ln \left( \frac{T}{ 1 \text{ year}} \right) \ , \label{eq:sigmap}
\end{align}
where $T$ is the length of the observation span and for MSPs $\ln \alpha_1 \sim -20 $, $\alpha_2 \sim 1$, $\alpha_3 \sim 2$ and $\alpha_4 \sim 2.4$. Throughout this work we assume that all pulsars are observed with a weekly cadence. In order to relate the empirical TOA noise model, Equation \ref{eq:sigmap}, to our Ornstein-Uhlenbeck frequency model, Equation \ref{eq:spinevol}, we set first $T = 1$ week in Equation \ref{eq:sigmap} to obtain an estimate of the TOA noise over a weekly time interval, i.e. the size of our numerical integration timestep. The frequency process noise parameter $\sigma^{(n)}$ can then be calculated for each pulsar where the standard deviation in the pulsar TOA can be related to the standard deviation in the pulsar frequency as 
\begin{eqnarray}
	\sigma^{(n)} \sim \sigma_{\rm TOA}^{(n)} \frac{f_{\rm p}^{(n)}}{T} \ . \label{eq:sigmap_f}
\end{eqnarray}
For our synthetic NANOGrav PTA, the median $\sigma^{(n)}$ calculated in this way is $\sigma^{(n)} = 4.28 \times 10^{-21} $ s. \newline 

As a sanity check, we can also calculate $\sigma^{(n)}$ using a complementary numerical approach to the empirical best-fit model outlined above. We can directly solve the state equation Equation \eqref{eq:spinevol} numerically using the \texttt{baboo} package \footnote{\url{https://github.com/meyers-academic/baboo}} so as to obtain a synthetic phase solution,
\begin{eqnarray}
	\xi^{(n)}(t) = \int_0^t dt' f^{(n)}_{\rm p}(t') \ ,
\end{eqnarray}
and generate TOAs and phase residuals. We calibrate the noise amplitude $\sigma^{(n)}$  to generate phase residuals that qualitatively resemble empirical phase residuals measured from real pulsars. We obtain empirical phase residuals from the UTMOST pulsar timing program \citep{UTMOST} from the  Molonglo Observatory Synthesis Telescope \citep{Bailes2017PASA...34...45B}. For the purposes of validating the $\sigma^{(n)}$ inferred from Equation \eqref{eq:sigmap_f}, it is sufficient at this stage to simply compare the synthetic and real phase residuals visually. Whilst it would also be possible to e.g. define some quantitative loss function (e.g. mean-squared error) between the two solutions and solve the optimisation problem to infer $\sigma^{(n)}$, for our purposes this is excessive. It is satisfactory to simply qualitatively compare the two solutions as a useful sanity check. We emphasise that we are not overly concerned with calculating the maximally accurate values for $\sigma^{(n)}$, but instead some reasonable values for constructing representative synthetic data. This approach of generating synthetic phase solutions and visually comparing with empirical solutions is also followed in \cite{Vargas}. In Figure \ref{fig:qualitative_compare} we compare the synthetic and empirical residuals for the NANOGrav pulsar J0030+0451. We can see that the synthetic and empirical residuals are qualitatively similar.
\begin{figure}
	\includegraphics[width=\columnwidth]{images/example_residuals_plot}
	\caption{Actual (left panels) and synthetic (right panels) phase residuals for NANOGrav millisecond pulsar J0030+0451. The actual residuals are obtained via UTMOST pulsar timing program \citep{UTMOST}. The synthetic residuals are generated by numerically solving Equation \eqref{eq:spinevol} with $\gamma^{(n)} = 10^{-13}$ and $\sigma^{(n)}$ inferred from Equations \eqref{eq:sigmap} and \eqref{eq:sigmap_f}. For all pulsars the two solutions are qualitatively similar, with comparable magnitudes in the residuals. }
	\label{fig:qualitative_compare}
\end{figure}
\subsubsection{Synthetic data generation}
We generate $N$ synthetic noisy timeseries, one for each pulsar, as follows:

\begin{enumerate}
	\item Integrate the state equations, Equations \eqref{eq:spinevol}--\eqref{eq:xieqn} numerically for the synthetic PTA described in Section \ref{sec:synt_pta}.
	\item Map from state space to measurement space via the measurement equation, Equation \eqref{eq:measurement}
	\item Add zero-mean Gaussian measurement noise to each timeseries, i.e. $f_{\rm m} ^{(n)} + \varepsilon^{(n)}$ where 	$\langle \varepsilon(t) \varepsilon(t') \rangle = \sigma_{\rm m}^2 \delta(t - t')$ for measurement noise covariance $\sigma_{\rm m}^2$.
\end{enumerate}
Equations \eqref{eq:spinevol}--\eqref{eq:xieqn} are solved by a Runge-Kutta It$\hat{\text{o}}$ integrator implemented in the \texttt{sdeint} python package \footnote{\url{https://github.com/mattja/sdeint}}. The static pulsar parameters  $\boldsymbol{\theta}_{\rm psr}$ are completely specified by our construction of the synthetic PTA outlined in Section \eqref{sec:synt_pta}. For this work we consider all pulsars to be observed for $T_{\rm obs} =10$ years, uniformly sampled with a weekly cadence. The measurement noise can be approximately related to the uncertainty in the pulse TOA, $\sigma_{\rm TOA}$, as
\begin{equation}
	\sigma_{\rm m} \sim f_{\rm p}^{(n)} \frac{\sigma_{\rm TOA}}{\text{T}} \ . 
\end{equation}
For a millisecond pulsar with $f_{\rm p}^{(n)} \sim 100$ Hz observed with a weekly cadence and $\sigma_{\rm TOA} \sim 1 \mu$s this gives $\sigma_{\rm m} \sim 10^{-10}$, whilst the very best pulsars might have $\sigma_{\rm TOA} \sim 10 $ ns or $\sigma_{\rm m} \sim 10^{-12}$. Throughout this work we fix $\sigma_{\rm m} = 10^{-11}$ Hz and take it to be known \textit{a priori} rather than a parameter to be inferred. Note that $f_{\rm m} ^{(n)}$ is modified by a different realisation of the measurement noise for each pulsar; whilst for our construction every pulsar is sampled at the same time and so would experience the same realisation of the noise, in actual pulsar astronomy different pulsars will be sampled at different times by different radio interferometers and so subject to different noise realisations. \newline 

In practice, in order to avoid numerical precision issues that arise when solving Equations \eqref{eq:spinevol}--\eqref{eq:xieqn} $\left ( \text{since } \sigma^{(n)} \ll f_{\rm p}^{(n)} \right)$ we first ``heterodyne" our state by subtracting the deterministic frequency evolution, equivalent to a change of variables:
\begin{equation}
	f_{\rm p}^{\prime (n)} = f_{\rm p}^{(n)} - f_{\rm em}^{(n)} \ .
\end{equation}  
We similarly heterodyne the measurement variable 
\begin{equation}
	f_{\rm m}^{\prime (n)} = f_{\rm m}^{(n)} - f_{\rm em}^{*(n)} \ ,
\end{equation}
where $ f_{\rm em}^{*(n)}$ is a guess of the deterministic spin-down based on the pulsar ephemeris. For synthetic data we can set $ f_{\rm em}^{*(n)} = f_{\rm em}^{(n)}$ but this is not true generally for real-world observations since the spin-down ephemeris is only known approximately. The measurement equation Equation \eqref{eq:measurement} that relates the state and measurement variables is then updated as 
\begin{equation}
	f_{\rm m}^{\prime (n)}(t) = f_{\rm p}^{\prime (n)}(t-d) g^{(n)}(t) -  f_{\rm em}^{(n)}(t-d)\left[ 1-g^{(n)}(t)\right] \ .
	\label{eq:measurement_cov}
\end{equation}
We emphasise that this change of variables is simply a convenient scaling to bring our numerical values into a reasonable dynamic range without having to use extended numerical floating point formats (e.g. long double, quadruple). It does not remove any degrees of freedom of the formulation. In particular both $f_{\rm em}^{(n)}(t_1)$
and $\dot{f}_{\rm em}^{(n)}(t_1)$ remain static parameters of the model, but now appear in the measurement equation rather than the state equation.


\subsection{Representative example}\label{sec:rep_example}
We initially characterise our method with a single example of a PTA which is perturbed by a GW from an individual quasi-monochromatic SMBHB source. The static GW source parameters $\boldsymbol{\theta}_{\rm gw}$ used for this injection are selected to be astrophysically reasonable and representative. The injected $\boldsymbol{\theta}_{\rm gw}$ are summarised in the ``Injected Values" column of Table \ref{tab:parameters_and_priors}. The static pulsar parameters $\boldsymbol{\theta}_{\rm psr}$ are as described in Section \ref{sec:synt_pta} and are also shown in Table \ref{tab:parameters_and_priors}. 

\subsubsection{Prior distributions}\label{sec:priors}
For the Bayesian methods used in this work, one must select reasonable priors, $\pi(\boldsymbol{\theta})$, for the complete set complete of static parameters. For $\pi(\boldsymbol{\theta}_{\rm gw})$ we choose standard non-informative priors \citep[e.g.][]{Bhagwat2021} as summarised in Table \ref{tab:parameters_and_priors}. The choice of $\pi(\boldsymbol{\theta}_{\rm psr})$ requires some additional discussion. \newline 


The parameters which govern the deterministic evolution of the pulsar spin frequency, $f_{\rm em}^{(n)} (t_1)$ and $\dot{f}_{\rm em}^{(n)} (t_1)$ are well-determined by existing radio timing observations. We can identify $f_{\rm em}^{(n)} (t_1)$ with the pulsar barycentric rotation frequency and $\dot{f}_{\rm em}^{(n)} (t_1)$ with the time derivative of barycentric rotation frequency quoted by pulsar observation catalogues. For the 12.5 year NANOGrav pulsars the median error in  the barycentric rotation frequency is $\sim 7 \times 10^{-13}$ Hz, and in the time derivative of barycentric rotation frequency is $\sim 1.8 \times 10^{-20}$ s $^{-2}$. Whilst it is then clear that $f_{\rm em}^{(n)} (t_1)$, $\dot{f}_{\rm em}^{(n)} (t_1)$ are typically measured with very high precisions, for this work we adopt a broader uniform prior, $\pm 10^3 \epsilon^{(n)}_{a}$ either side of the true value, where $\epsilon^{(n)}_{a}$ is the error for that pulsar quoted in the ATNF catalogue and the subscript $a = \{ f, \dot{f} \}$ identifies the error as being in $f_{\rm em}^{(n)} (t_1)$, or $\dot{f}_{\rm em}^{(n)} (t_1)$ respectively. In this way we can test how well our method performs without requiring exceptionally precise and accurate measurements of the pulsar parameters to be made \textit{a priori}. Instead we consider the pulsar parameters similarly to the GW source parameters and estimate them optimally within a consistent framework. Adopting looser priors in this way allows us to subject our method to a more stringent test and confirm that we still accurately estimate GW parameters without highly accurate initial estimates of $f_{\rm em}^{(n)} (t_1)$ and $\dot{f}_{\rm em}^{(n)} (t_1)$. \newline 


The pulsar distances $d^{(n)}$ are typically not as well constrained as $f_{\rm em}^{(n)} (t_1)$ and $\dot{f}_{\rm em}^{(n)} (t_1)$, with uncertainties typically on the order of $\sim 10 \%$ \citep{Arzoumanian2018ApJS..235...37A,Yao2017}. However for this work, whilst the pulsar distance is used when generating synthetic data, as discussed in Section \ref{sec:parameter_estim}, the pulsar distance is not used for our inference model and so we do not need to set a prior on $d^{(n)}$. Similarly we do not set a prior on $\gamma^{(n)}$; since $[\gamma^{(n)}]^{-1} \gg T_{\rm obs}$ this means that $\gamma^{(n)}$ is effectively ``unobservable" over the decadal timescales that we are interested in. That is, for $T_{\rm obs}$ =10 years the solution of Equation \eqref{eq:spinevol} is effectively independent of the choice of $\gamma^{(n)}$ as long as the condition $[\gamma^{(n)}]^{-1} \gg T_{\rm obs}$ is satisfied. It is therefore sufficient to consider $\gamma^{(n)}$ to be known \textit{a priori} and set it at its true injected value. We briefly explored setting an uninformative prior on $\gamma^{(n)}$ over e.g. LogUniform($10^{-15}, 10^{-10}$) s$^{-1}$ as well as setting $\gamma^{(n)}$ at some fixed value away from the true injected value (e.g. set $\gamma^{(n)} = 10^{-14} \text{s}^{-1}$ rather than $10^{-13} \text{s}^{-1}$) but the results are unchanged. The majority of pulsars in our synthetic PTA have $\sigma^{(n)} \sim 10^{-20} - 10^{-22} \text{s}^{-5/2}$ as calculated from Equations \eqref{eq:sigmap} and \eqref{eq:sigmap_f}. For these pulsars we set an uninformative broad prior of LogUniform($10^{-23}, 10^{-19}$ $\text{s}^{-5/2}$). The single exception is PSR J1939+2134 which has a particularly large $\dot{f}_{\rm em}^{(n)} (t_1)$ compared to the other pulsars in the array and so $\sigma \sim 10^{-16} \text{s}^{-5/2}$. For our artificial dataset we set $\sigma = 10^{-21} \text{s}^{-5/2}$ for this pulsar in order to bring the process noise for all pulsars into a consistent range that can be described by a single constrained prior. \newline 


Since we are not setting priors on $\gamma^{(n)}$ or $d^{(n)}$ this reduces the dimensionality of the parameter space to $7 + 3N$. We use the notation $\boldsymbol{\theta}_{\rm psr, reduced}$ to refer to the reduced parameter space, c.f. Equation \ref{eq:psrparams}. Explicitly, 
\begin{equation}
	\boldsymbol{\theta}_{\rm psr, reduced} = \left \{ f_{\rm em}^{(n)}(t_1),\dot{f}_{\rm em}^{(n)}(t_1),\sigma^{(n)}\right\}_{1\leq n \leq N} \ .
\end{equation}
All the injected static parameters and their corresponding priors for this representative example are summarised in Table \ref{tab:parameters_and_priors}.
\begin{table*}
	\centering
%	\resizebox{\textwidth}{!}{%
%	\renewcommand{\arraystretch}{1.0} % Default value: 1
	\begin{tabular}{lccll}
		\toprule
		&Parameter & Injected Values & Units & Prior  \\
		\hline
		\multirow{7}{2mm}{$\boldsymbol{\theta}_{\rm gw}$} & $\Omega$       & $5 \times 10^{-7}$ & Hz & LogUniform($10^{-9}$, $10^{-5}$) \\
	  & $\alpha$          & $1.0$  & radians & Uniform($0, 2 \pi $)\\
	  & $\delta$              & $1.0$  & radians & Uniform($-\pi/2, \pi/2$) \\
	  & $\psi$              & $2.50$ & radians & Uniform($0, 2 \pi $) \\
	  & $\Phi_0$          & $0.20$ & radians & Uniform($0, 2 \pi $) \\
	  & $h_0$            & $5 \times 10^{-15}$ & - & LogUniform($10^{-15}$, $10^{-9}$) \\
	  & $\iota$             & $1.0$ & radians & Uniform($0, \pi$) \\ 
		\hline
		\multirow{5}{2mm}{$\boldsymbol{\theta}_{\rm psr}$} & $f_{\rm em}^{(n)} (t_1)$       & $f_{\rm ATNF}^{(n)}$ & Hz & Uniform$\left( f_{\rm ATNF}^{(n)} - 10^3 \epsilon^{(n)}_{f}, f_{\rm ATNF}^{(n)} + 10^3 \epsilon^{(n)}_{f} \right)$ \\
		& $\dot{f}_{\rm em}^{(n)} (t_1)$       & $\dot{f}_{\rm ATNF}^{(n)}$ & s$^{-2}$ & Uniform$\left( \dot{f}_{\rm ATNF}^{(n)} - 10^3 \epsilon^{(n)}_{\dot{f}}, \dot{f}_{\rm ATNF}^{(n)} + 10^3 \epsilon^{(n)}_{\dot{f}} \right)$ \\
		&  $d^{(n)}$       &$d_{\rm ATNF}^{(n)}$  & m & - \\
		& $\sigma^{(n)}$              & $\sigma_{\rm sc}^{(n)}$ & $s^{-5/2}$ & LogUniform($10^{-23}, 10^{-19}$) \\
		& $\gamma^{(n)}$              & $10^{-13}$ & s$^{-1}$ & - \\
		\bottomrule
	\end{tabular}
	\caption{Summary of injected static parameters used for generating synthetic data in the representative example of Section \ref{sec:rep_example}, along with the choice of prior used for Bayesian inference on each parameter. The subscript ``ATNF" denotes values which have been obtained from the ATNF pulsar catalogue as described in Section \ref{sec:synt_pta}. The subscript ``sc" indicates that the injected value has been calculated using the empirical timing model, Equations \eqref{eq:sigmap} and \eqref{eq:sigmap_f} from \protect \cite{Shannon2010}. The quantities $\epsilon^{(n)}_{f}$ and $\epsilon^{(n)}_{\dot{f}}$ are the errors in $f^{(n)}_{\rm em} (t_1)$ and $\dot{f}^{(n)}_{\rm em} (t_1)$ respectively, as quoted in the ATNF catalogue.}
	\label{tab:parameters_and_priors}
\end{table*}




\subsubsection{Parameter estimation}\label{sec:parameter_estim}
From Equation \eqref{eq:g_func_trig} it can be seen that the measurement equation generally separates into two cosine terms. The first term, $\cos(-\Omega t + \Phi_0)$, depends only on the GW source parameters and is shared across all pulsars. The argument of the cosine corresponds to the GW phase at the observer on Earth.  Conversely the second term, $\cos \left(-\Omega t +\Phi_0 + \Omega \left(1 + \boldsymbol{n}\cdot \boldsymbol{q}^{(n)} \right)  d \right)$, also depends on $d^{(n)}$ and $\boldsymbol{q}^{(n)}$ and so varies between pulsars. The argument of the cosine corresponds to the GW phase at each the individual pulsar. The first and second terms are commonly referred to as the ``Earth term" and ``pulsar term" respectively. Whilst the Earth term is phase coherent between all pulsars and so can be summed across the array to increase the total signal-to-noise, the pulsar terms each have individual phases and in standard PTA analysis are typically considered as a source of self noise and dropped from the analysis \citep[e.g.][]{Sesana2010,Babak2012,Petiteau2013,Zhu2015,Taylors2016,Goldstein2018,Charisi2023arXiv230403786C} at the expense of a modestly reduced detection probability ($\sim 5 \%$) and the introduction of a bias in the sky localisation \citep{Zhupulsarterms,Chen2022}. In this work we follow the standard analysis approach and drop the pulsar terms from our model. Explicitly the measurement equation used in the Kalman filter is
\begin{equation}
		f_{\rm m}^{(n)}(t) = f_{\rm p}^{(n)}(t-d) g^{(n)}_{\rm Earth}(t) \ , 
		\label{eq:measuremen_earth}
	\end{equation}
	with
	\begin{equation}
		g^{(n)}_{\rm Earth}(t) = 1 - \frac{1}{2} \frac{ H_{ij}q^{i,(n)} q^{j,(n)}}{(1 + \boldsymbol{n}\cdot \boldsymbol{q}^{(n)}) }  \cos(-\Omega t +\Phi_0)  \ .
		\label{eq:g_func_trig_earth}
	\end{equation}
	We defer the inclusion of the pulsar terms in the measurement equation to a future work. As discussed in Section \ref{sec:priors} this choice reduces the dimensionality of the parameter estimation problem since the measurement equation, Equation \eqref{eq:measurement}, is no longer a function of the pulsar distance.  We stress that the pulsar terms are dropped only for purposes of Bayesian inference, i.e. from the Kalman filter model that feeds into the nested sampling algorithm. The generated synthetic data that we use to test our method does include the pulsar term in full. Initially we consider a single noise realisation of the synthetic data for the representative example system described in Table \ref{tab:parameters_and_priors}. We apply the Kalman filter using the Earth terms only measurement equation, Equation \eqref{eq:measuremen_earth} in conjunction with nested sampling in order to infer the posterior distributions in each of the parameters. \newline 

 The results are shown in Figure \ref{fig:corner_plot_1} for the seven parameters of  $\boldsymbol{\theta}_{\rm gw}$. The histograms shown in the Figure are the one-dimensional posteriors for each parameter, marginalized over the set of all other parameters, where the dashed vertical blue lines show the 0.16 and 0.84 quantiles and the solid orange line the true injection value. The two-dimensional contours denote the (0.5, 1, 1.5, 2)-sigma equivalent contours. It is evident that for this representative example with strain $h_0 = 5 \times 10^{-15}$ that we are able to estimate all the static parameters of the system using our method, with the injected value contained within the 90\% credible interval for all of the parameters. 
 
 
 
 

 For some of the parameters the estimated posterior is approximately symmetric about the true injected value (e.g. $\Omega$). In this case the posterior median and the injected value are approximately coincident. For other parameters (e.g. $\iota$) the distribution is not symmetric about the injected value and the posterior median and the injected value are not coincident. The median value of the posterior for $\iota$ is shifted by $\sim 0.35$ rad relative to the injected value, although the injected value does still remain inside the 90\% credible interval. Similar effects are seen, albeit with a smaller shift, in other parameters such as $\delta$ and $\alpha$. For a single realisation of the noise it is not clear if this discrepancy is a systematic effect, i.e. a bias in the parameter estimate, or else just a random variation specific to this particular noise realisation. We explore this further in Section \ref{sec:multiple_noise} and Section \ref{sec:bias} and show that this is a bias that results from dropping the pulsar terms, similar to the bias reported in \cite{Zhupulsarterms}. Similar results are derived for the the 3$N$ parameters of $\boldsymbol{\theta}_{\rm psr, reduced}$ and the parameters are generally recovered unambiguously, but we do not display the resulting posterior distributions here since the inference of $\boldsymbol{\theta}_{\rm gw}$ is the main focus of this work. We are able to simultaneously estimate both $\boldsymbol{\theta}_{\rm gw}$ and $\boldsymbol{\theta}_{\rm psr, reduced}$. 
 
 
\begin{figure*}
	\includegraphics[width=\textwidth, height =\textwidth ]{images/small_h_posterior_10}
	\caption{Posterior distribution for the GW source parameters $\boldsymbol{\theta}_{\rm gw}$ for the representative system described in Table \ref{tab:parameters_and_priors}, for a single realisation of the system noise. The vertical orange lines indicate the true injected values. The contours in the 2D histograms denote the (0.5, 1, 1.5, 2)-$\sigma$ levels. We are able to accurately estimate each parameter of interest. We pot the scaled variables $\Omega_{\rm nHz} = \Omega \times 10^{9}$ Hz and $h_{0, \times 10^{15}} = h_0 \times 10^{15}$. Note that the $x$-axis scaling of the one-dimensional posteriors does not span the total prior space.}
	\label{fig:corner_plot_1}
\end{figure*}

%\begin{figure*}
%	\includegraphics[width=\textwidth, height =\textwidth ]{images/representative_example_v2_GW}
%	\caption{Posterior distribution for the GW source parameters $\boldsymbol{\theta}_{\rm gw}$ for the representative system described in Table \ref{tab:parameters_and_priors}, for a single realisation of the system noise. The vertical orange lines indicate the true injected values. The contours in the 2D histograms denote the (0.5, 1, 1.5, 2)-$\sigma$ levels. We are able to accurately estimate each parameter of interest. We pot the scaled variables $\Omega_{\rm nHz} = \Omega \times 10^{9}$ Hz and $h_{0, \times 10^{12}} = h_0 \times 10^{12}$.}
%	\label{fig:corner_plot_1}
%\end{figure*}



\subsubsection{Multiple noise realisations} \label{sec:multiple_noise}
\begin{figure*}
	\includegraphics[width=\textwidth, height =\textwidth]{images/stacked_GW_plot_small_h_definitive2}
	\caption{As Figure \ref{fig:corner_plot_1} but for 9 realisations of the noise processes. The inferred posterior distributions show strong agreement between the different noise realisations for the majority of static parameters. The exceptions are $\iota$ and $h$ which exhibit a larger degree of variance due to the weak identifiability between these two parameters c.f. Figure \ref{fig:likelihood_surface}.} 
	\label{fig:corner_plot_2}
\end{figure*}
The above discussion was for a single realisation of the noise processes. It is important to confirm that our method is robust against different realisations of the noise and that the specific realisation of the noisy data used in Sections \ref{sec:parameter_estim} is not particularly advantageous or convenient for our method. In this Section we confirm that we are able to infer comparable results for different noise realisations. To this end we take our representative example from Table \ref{tab:parameters_and_priors} and generate 1000 realisations of the process noise and measurement noise. For each realisation of the data we can then independently estimate the static parameters, $\boldsymbol{\theta}$. In Figure \ref{fig:corner_plot_2} we show the results for the  estimated values of $\boldsymbol{\theta}_{\rm gw}$ for nine realisations of the noise. This figure is analogous to the single noise realisation of Figure \ref{fig:corner_plot_1}. We plot only 9 realisations of the noise rather than the full set of 1000 realisations so as to not overcrowd the figure. As in Section \ref{sec:parameter_estim} the estimates of $\boldsymbol{\theta}_{\rm psr, reduced}$ are recovered unambiguously across the 1000 noise realisations and for brevity we do not show the results here. \newline 


We can see from Figure \ref{fig:corner_plot_2} that the results from these 9 noise realisations agree well with the single realisation result that we saw in  Figure \ref{fig:corner_plot_1}. Considering the one-dimensional marginalized posteriors, the inferred probability distributions of the parameters broadly overlap across the different noise realisations. For the vast majority of parameters and noise realisations the injected value is contained within the 90 \% credible interval. \newline 


We now consider the complete set of $10^3$ noise realisations, rather than the subset of nine realisations in the preceding discussion. For each realisation of the noise, for each parameter, we infer a marginalised one-dimensional posterior. We want to compare these posteriors for different noise realisations and evaluate whether our method can consistently and reliably converge to comparable posteriors. To this end we use the the Wasserstein distance \citep[WD;][]{Wasserstein,Villani2009} from optimal transport theory which defines an intuitive notion of similarity between probability distributions. The WD is a popular metric in machine learning \citep{2017arXiv170107875A}, climate modelling \citep{2022JCli...35.1215P,2023QJRMS.149..843K}, computational biology \citep{GONZALEZDELGADO2023168053} and geophysics \citep{2023GeoRL..5003880M}. A full review of the Wasserstein distance, which may be unfamiliar to some readers, is presented in Appendix \ref{sec:wasserstein}. The WD is the cost of an optimal strategy for moving probability mass between two distributions from position $x$ to position $y$, with respect to some cost function $c(x,y)$. Throughout this work we use the first moment of the Wasserstein distance $W_1(\mu,\nu)$ which is defined between one-dimensional probability distributions $\mu$ and $\nu$ as
\begin{eqnarray}
	W_1(\mu,\nu)=  \inf_{\lambda \in \Gamma(\mu, \nu)} \int |x-y| d \lambda (x,y)
\end{eqnarray}
where $\lambda(x,y)$ is the transport plan, $\Gamma(\mu, \nu)$ is the set of all couplings of $\mu$ and $\nu$ and $ |x-y|$ defines the cost function.  \newline 


For each parameter in $\boldsymbol{\theta}_{\rm gw}$ we calculate $W_1$ between every pair of posteriors across our $10^3$ noise realisations. To form a single metric we then take the median value for each parameter across these pairwise calculations. The results are shown in Table \ref{tab:Wasserstein}.
\begin{table}
	\centering
		\begin{tabular}{ccll}
			\toprule
			Parameter & Injected Values & Units & WD  \\
			\hline
			 $\Omega$     &   $5 \times 10^{-7}$ & Hz & $10^{-9}$ \\
			 $\Phi_0$          & $0.20$ & rad & $0.13$ \\
			 $\psi$              & $2.50$ & rad & $0.16$ \\
			 $\iota$             & $1.0$ & rad & $0.14$ \\ 
			 $\delta$              & $1.0$  & rad & $0.09$ \\
			 $\alpha$          & $1.0$  & rad & $0.17$\\
			 $h_0$            & $5 \times 10^{-15}$ & - & $8 \times 10^{-16}$ \\
			\bottomrule
		\end{tabular}
		\caption{}
		\label{tab:Wasserstein}
	\end{table}
The WD has an additional useful physical interpretation given by the Monge-Kantorovich duality:
\begin{eqnarray}
	| \boldsymbol{E}(X_{\mu} )-\boldsymbol{E}(Y_{\nu} ) | \leq W_1(\mu, \nu) \label{eq:WDdefn}
\end{eqnarray}
where $X_{\mu}$ and $Y_{\nu}$ are random variables of the distributions $\mu$ and $\nu$ respectively, and $\boldsymbol{E}$ denotes the expected value. We can see that the WD bounds the difference in the expected values. For example, in Table \ref{tab:Wasserstein} we report a median $W_1 = 0.14$ rad for $\iota$. This tells us that the across all noise realisations the difference in the expected value of $\iota$ is less than 1 rad. We can see that the bounds from the WD are tight for all parameters; as a percentage of the width of the prior space, the difference in the expected values for the distributions of each parameter are $\lesssim 2 \%$. 

See also Figure \ref{fig:pairwise_wasserstein}

\begin{figure*}
	\setkeys{Gin}{width=\linewidth}   
	
	\begin{subfigure}[b]{0.22\textwidth}
			\includegraphics[width=\textwidth]{images/WD_0}
			\caption{$\Omega$}
		\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.22\textwidth}
			\includegraphics[width=\textwidth]{images/WD_1}
			\caption{$\Phi_0$}
		\end{subfigure}
	\hfill	
	\begin{subfigure}[b]{0.22\textwidth}
			\includegraphics[width=\textwidth]{images/WD_2}
			\caption{$\psi$}
		\end{subfigure}
    \hfill
	\begin{subfigure}[b]{0.22\textwidth}
			\includegraphics[width=\textwidth]{images/WD_3}
			\caption{$\iota$}
		\end{subfigure}
	\medskip
	\begin{subfigure}[b]{0.3\textwidth}
			\includegraphics[width=\textwidth]{images/WD_4}
			\caption{$\delta$}
		\end{subfigure}
	\hfill	
	\begin{subfigure}[b]{0.3\textwidth}
			\includegraphics[width=\textwidth]{images/WD_5}
			\caption{$\alpha$}
		\end{subfigure}
	\hfill	
	\begin{subfigure}[b]{0.3\textwidth}
			\includegraphics[width=\textwidth]{images/WD_6}
			\caption{$h$}
		\end{subfigure}
	\caption{Wassersteins}\label{fig:pairwise_wasserstein}
\end{figure*}









if we compare two posteriors for $\iota$ calculated for two different noise realisations, a WD = 1.0 rad tells us that the difference in the expected value of from the two distributions is less than 1 rad. \newline 

Considering now the 



Wd tells us only how well different distributions agreee. It doesnt tell use about the accuray of the posteriors themselves. c.f. bias










As in the singe noise case, there are tentative signs in a bias 





Considering now the 




$\Omega, \Phi_0, \psi, \delta$ and $\alpha$ 






%Moreover, the variance of each of the individual one-dimensional posteriors is generally low i.e. each of the individual distributions are narrow compared to the prior space. For each different noise realisation the method infers a consistent maximum \textit{a posteriori} probability (MAP) estimate. Conversely for the parameters $\iota$ and $h_0$ the inferred one-dimensional posteriors do not broadly overlap are not consistent across different noise realisations and the variance of an individual posterior is generally larger than for the other parameters. That is to say, we infer very different MAP estimates of these parameters depending on the particular realisation of the noise. \newline 



We now consider the complete set of 








 











For this injected strain ($h_0 = 10^{-12}$) the signal-to-noise ratio (SNR) is large (c.f. Figure \ref{fig:bayes}) and consequently the posteriors are typically narrow compared to the prior space and well described by their median value. To compare each of the posteriors across different noise realisations, 





%
%
%we consider the normalised standard deviation in the set of $10^3$ median values i.e. 
%\begin{equation}
%	\rho \left( \boldsymbol{\theta}\right)= \frac{1}{\mu(\boldsymbol{\theta})} \sqrt{ \frac{\sum_{i=1}^{i=10^3}\left[x_i(\boldsymbol{\theta}) - \mu(\boldsymbol{\theta}) \right]}{10^3}} 
%\end{equation} 
%where $\mu(\boldsymbol{\theta})$ is the mean value across the distribution of $10^3$ samples for parameter $\boldsymbol{\theta}$, and $x_i$ the value of the $i$-th sample. For the parameters $\{\Omega, \Phi_0, \psi, \delta, \alpha \}$ we have $\rho \sim \{4 \times 10^{-5}, 0.03,0.004,0.03,0.02 \}$ respectively. We can therefore see that the method is able to reliably converge to a consistent MAP estimate. Conversely, as we saw before, the MAP estimates for $\iota$ and $h_0$ are not consistent across different noise realisations, with $\rho \sim 0.3$ and $\rho \sim 0.1$ respectively. This is due to the weak-identifiability issue that we have discussed. \newline
%
%
%
%
%







We saw previously strong biases in $\iota$ and $h_0$ when considering just 9 noise realisations. These biases persist with a similar magnitude when we consider the full set of $10^3$ noise realisations. Moreover, smaller biases are also observed in $\psi$ ($\sim 0.1$ radians) and $\alpha$ ($\sim 0.04$ radians) as well as smaller still biases in $\delta$ and $\Phi_0$. These biases are a result of dropping the pulsar terms from the measurement equation and will be discussed in Section \ref{sec:bias}








\subsubsection{Detection} \label{sec:detection}
We frame the problem of claiming a detection of a GW in the noisy data in terms of a Bayesian model selection procedure as described in Section \ref{sec:model_selection}. $\mathcal{M}_1$ is the Earth-terms only model, i.e. the state-space model with a Kalman filter using Equation \eqref{eq:measuremen_earth}. The Bayes factor, $\beta$, as defined in Equation \eqref{eq:bayes} is presented in Figure \ref{fig:bayes} for our representative system, where we now vary the magnitude of the GW strain, $h_0$. The noise processes in the synthetic data are identical realisations for each value of $h_0$; the only change in the data is the change in $h_0$. We can see that for $\beta >10$ there is an approximate log-linear relationship between $\beta$ and $h_0$ where the GW source is easily detectable with decisive evidence ($\beta \sim 100$) for $h_0 \gtrapprox 10^{-14}$. We take $\beta = 10$ as a tolerance cut-off above which we can accept $\mathcal{M}_1$ and claim a detection of the GW. For this system, given this realisation of the noise, the minimal detectable strain is $\sim 3.9 \times 10^{-15}$. This minimal detectable strain is of course particular to this system and will be influenced in general by e.g. $T_{\rm obs}$, $\sigma_{\rm m}$ as well as the parameters of the GW source such as its location on the sky. \newline 

There is an evident sparsity and steep drop-off of $\beta$ for values of $h_0 \lesssim 3.9 \times10{-15}$. The steep drop off is due to the two competing models becoming increasingly indistinguishable as the strain signal decreases and the measurement noise starts to dominate. The sparsity is due some of the $\beta$ value becoming negative at these points.This is a noise artefact of the nested sampling method. For these points the noise in the sampler starts to dominate, the sampler converges sub-optimally, and the hierarchical relationship between $\mathcal{M}_0$ and  $\mathcal{M}_1$ fails. That is, the requirement that $\mathcal{Z}(\boldsymbol{Y} | \mathcal{M}_1) > \mathcal{Z}(\boldsymbol{Y} | \mathcal{M}_0)$ no longer holds. There is nothing special about these particular points; if one recreates the $\beta - h_0$ curve by rerunning the nested sampler these sparse locations appear at different values of $h_0$, for $\beta < 10$. For $\beta > 10$ the sampling noise is sufficiently small with respect to the signal and the model hierarchy holds. Increasing the number of live points $n_{\rm live}$ used by the nested sampler improves the performance at small values of $h_0$ since as discussed in Section \ref{sec:nested_sampling} the uncertainties in $\mathcal{Z}$ scale as $\mathcal{O}(1/ \sqrt{n_{\rm live}})$. For the results presented here we set $n_{\rm live} =2000$. 
\begin{figure}
	\includegraphics[width=\columnwidth]{images/CanonicalBayesPlot2000}
	\caption{Bayes ratio $\beta$ between the competing models $\mathcal{M}_1$ (GW present in data) and $\mathcal{M}_0$ (GW not present in data) at different GW strain magnitudes $,h_0$, for the representative example summarised in Table \ref{tab:parameters_and_priors}. The horizontal grey dashed line labels the detection threshold of $\beta = 10$. The minimal detectable strain, below which $\beta < 10$, is $\sim 3.9 \times 10^{-15}$. Gaps in the data below $\beta=10$ occur due to noise in the sampler breaking the hierarchical relationship between $\mathcal{M}_0$ and $\mathcal{M}_1$.}
	\label{fig:bayes}
\end{figure}


















\subsection{Exploring a broader parameter space} \label{sec:parameter_space}
\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{images/pp_plot_new}
	\caption{PP plot for 200 simulated GW sources for a subset of parameters of $\boldsymbol{\theta}_{\rm gw}$, randomly drawn from the prior distributions of Table \ref{tab:parameters_and_priors}. Each coloured line corresponds to a different parameter of $\boldsymbol{\theta}_{\rm gw}$. The parameters $h_0$ and $\iota$ are fixed at $5 \times 10^{-14}$ and 1.0 rad in order to maintain an approximately constant SNR. The grey shaded contours labels the $1,2,3$-$\sigma$ confidence intervals. Well estimated posteriors should fall along the diagonal $y=x$. Many parameters show evidence of being over-constrained due to a modelling bias. }
	\label{fig:parameter_space}
\end{figure}
We have so far focussed on a single representative system, summarised in Table \ref{tab:parameters_and_priors}. It is also important to test the method in different regions of the parameter space. To this end we consider 200 injections for different sets of parameter values where we fix $h_0 = 5 \times 10^{-15}$, $\iota =1.0$ and draw the remaining five parameters of $\boldsymbol{\theta}_{\rm gw}$ from the prior distributions described in Table \ref{tab:parameters_and_priors}. We fix $h_0$ and $\iota$ in order to maintain an approximately constant SNR across the parameter space. For each simulated injection we can then attempt to recover the posterior distributions for each parameter. To summarise the results across the parameter space we use a parameter-parameter (PP) plot \citep{doi:10.1198/106186006X136976}. A PP plot describes the fraction of the total number of injected parameters which are included within a given credible interval of the estimated posterior with respect to the credible interval itself. In the ideal case the PP plot should be a diagonal line, indicating that $x$-percentage of the simulated injections fall within the $x$-percentage credible interval. The results are shown in Figure \ref{fig:parameter_space}. The shaded grey contours enclose the $1\sigma$, $2\sigma$, and $3\sigma$ significance levels, given 200 injections."
We can see that only $\Omega$ falls within the $3\sigma$ shaded region. The other parameters deviate from the $y=x$ diagonal. The effect is most pronounced for $\alpha$ and $\delta$ with more modest deviations for $\psi$ and $\Phi_0$. The shape of the graph indicates that the posteriors for these parameters are over-constrained; there are fewer injections contained within high value credible intervals than would be expected statistically, and there are more injections contained within the low value credible intervals. This is an result of the bias that we observed in Section \ref{sec:multiple_noise}; the posteriors inferred for these parameters are generally highly confident, i.e. narrow, but are systematically biased away from the true injection values. This manifests in the PP plot as posteriors which are overly precise (narrow) to contain the injected value within the appropriate credible interval. An in-depth discussion on the origin of this bias is given in Section \ref{sec:bias}. 




\subsection{Identifiability and bias}


\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{images/stacked_GW_plot_iota_h}
	\caption{}
	\label{}
\end{figure}


\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{images/likelihood_surface}
	\caption{Likelihood $\log \mathcal{L}$ (Equation \ref{eq:likelihood}) surface across the $\iota - h_0$ parameter space for a single noise realisation. The red point labels the location of the likelihood maxima. The likelihood surface has been normalised with respect to the absolute value of the maxima. A strong likelihood ridge is evident in the parameter space where the Kalman filter produces similar likelihood values, making it difficult for sampling algorithms to converge to a consistent value.}
	\label{fig:likelihood_surface}
\end{figure}



The posteriors for $\iota$ and $h_0$ do not overlap for the different noise realisations due to these parameters being only weakly-identifiable. Identifiability refers to whether it is theoretically possible to infer unique parameter values of the model, given the measured data and the model structure \citep{e5be7c83a0d24500826f6e1b414d1733}. Sources of non-identifiability are generally categorised as either ``structural" (arising from the structure of the model) or ``practical" ( arising from insufficient data or measurement errors) \citep{GUILLAUME2019418}. Regarding $\iota$ and $h_0$, we are concerned with structural identifiability. Indeed, one might initially suspect that $\iota$ and $h_0$ could have structural identifiability issues; from Equations \eqref{eq:hphx}, \eqref{eq:hphx2} we can see that there is a weak degeneracy between $\iota$ and $h$. For example, from Equation \eqref{eq:hphx2} it is not clear if a larger value of the cross polarisation strain $h_{\times}$ is due to the system having a larger strain amplitude $h_0$, or a different inclination $\iota$. This degeneracy is only broken by the relation for $h_{+}$, Equation \eqref{eq:hphx}. However, it can be shown (Appendix \ref{appendix_identifiability}) that $\iota$ and $h_0$ are in fact structurally identifiable, but with the caveat that they are only weakly-identifiable. That is to say the $\iota-h_0$ likelihood surface plateaus to a ridge with a non-zero gradient close to the maximum likelihood solution. This likelihood ridge is presented in Figure \ref{fig:likelihood_surface} for a particular noise realisation. Whilst a single, unique maxima exists (labelled by the red point in the figure), along the ridge in the parameter space the likelihood values are all very similar. Consequently it is difficult for the nested sampling algorithm to select a particular point in this plateau and instead effectively trades off accuracy in one parameter against accuracy in other, depending on the particular realisation of the noise. If we fix one of the parameters at its true value, taking a slice through the likelihood surface, it is then possible to identify a particular point in the plateau and the the posteriors for the different noise realisations overlap. This is demonstrated in Figure \ref{fig:iota} where we plot the marginalized one-dimensional posterior of $\iota$ for 9 realisations of the noise in both the original case where $h_0$ is a free parameter (equivalent to the one-dimensional posterior for $\iota$ in Figure \ref{fig:corner_plot_2}) and in the case where we hold $h_0$ fixed at its injection value, $h_0 = 10^{-12}$. We can see that whilst the variance between the individual posteriors is large in the original case, once we fix $h_0$ the variance decreases dramatically and the sampling algorithm repeatedly converges consistent estimates of $\iota$. For the fixed $h_0$ case, evident in Figure \ref{fig:iota} is a strong bias of $\sim 0.35$ radians in the estimates for $\iota$ relative to the true injected value. Whilst the variance in the estimates across the noise realisations has decreased, the mean accuracy of the estimates has also decreased. An equivalent bias in $h_0$ is observed if we fix $\iota$. This bias is a result of dropping the pulsar terms from our measurement equation and is discussed in Section \ref{sec:bias}. \newline 















\subsection{Bias by dropping pulsar terms}\label{sec:bias}
\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{images/likelihood_iota_new}
	\caption{Variation in the log likelihood returned by the Kalman filter using the Earth terms model (Equation \ref{eq:measuremen_earth}, blue line), the pulsar terms model (Equation \ref{eq:measurement}, orange line), and the Earth terms model for Earth terms only synthetic data (green line), with respect to the inclination $\iota$, over the prior space. All other parameters are fixed at their true injected value from Table \ref{tab:parameters_and_priors}. The coloured dashed vertical lines label the location of the likelihood maxima for their corresponding model. For the Earth-terms model the likelihood maxima does not coincide with the injected value ($\iota = 1.0$). For the pulsar-terms model the location of the maxima and injected value do coincide. 10 noise realisations are plotted but the solutions are completely overlaid.}
	\label{fig:likelihood_surface_iota}
\end{figure}

\begin{figure*}
	\includegraphics[width=\textwidth, height =\textwidth]{images/large_h_example}
	\caption{} 
	\label{fig:bias_for_large_h}
\end{figure*}

Evident in the preceding discussion is the fact that for some of the $\boldsymbol{\theta}_{\rm gw}$ parameters the inferred value (e.g. the median of the one-dimensional marginalised posterior) is biased away from the true injection value. This effect is most severe for $\iota$ and $h_0$ but also present to a lesser extent in other static parameters such as $\delta,\alpha$ and $\psi$, and additionally to an even smaller extent in $\Phi_0$. In this Section we demonstrate how this bias results from the dropping of the pulsar terms described in Section \ref{sec:parameter_estim}. \newline 



for low signal bias is covered by noise


In Figure \ref{fig:likelihood_surface_iota} we plot the variation in the log-likelihood returned by the Kalman filter, Equation \eqref{eq:likelihood}, as we vary $\iota$ across the prior space, holding all other parameters constant at the true injected value of the representative example system, Table \ref{tab:parameters_and_priors}. We do this for 10 separate realisations of the system noise. We consider three separate situations: \textit{(i)} The solid blue line is the likelihood curve with just the Earth-terms included (i.e. using Equation \ref{eq:measuremen_earth} in the Kalman filter), \textit{(ii)} the solid orange line is the likelihood curve with the additional pulsar terms included (i.e. using Equation \ref{eq:measurement}), \textit{(iii)} the solid green line is the solution where we drop the pulsar terms from both the synthetic data and the measurement equation. Whilst we have not used the nested sampling method with either solutions \textit{(ii)} or \textit{(iii)} in this work, we are able to run the Kalman filter either using the pulsar terms in the model or else dropping them from the synthetic data consider how the resulting likelihood varies for different parameter values. The dashed lines show the location of the likelihood maxima for each of the likelihood solutions; finding the location of the maxima across all static parameters is effectively the goal of any likelihood based inference method, such as nested sampling. \newline  

The key observation from Figure \ref{fig:likelihood_surface_iota} is that for the Earth-terms only solution the location of the likelihood optima and the location of the injected value are not the same. Consequently Bayesian likelihood inference techniques settle in optima that do not necessarily align with the true injection value. This is the origin of the bias in the one-dimensional marginalised posteriors that we observe.  For the Earth-terms solution the optima of the likelihood curve lies around $\iota \sim 0.7$ radians, whereas the injected value was $\iota = 1.0$ radians, This difference is comparable to the bias observed in the right-hand panel of Figure \ref{fig:iota} where the median of the marginalised posterior for $\iota$ was $\sim 0.65$ radians. The discrepancy between $\iota \sim 0.7$ in the log-likelihood curve and $\iota \sim 0.65$ in the nested sampling inference is a result of the likelihood curves being a one-dimensional representation of a multidimensional problem. The exact shape of the likelihood curve naturally depends on the values of all of the other parameters that we hold constant. In the nested sampling case the estimate for $\psi$ is sightly biased at $\psi \sim 2.60$ radians compared to the true injected value of $\psi = 2.50$ radians that is used for the results of Figure \ref{fig:likelihood_surface_iota}. \newline 


In contrast to the Earth-terms solution, for the solution which includes the pulsar terms the optima of the likelihood curve now aligns with the true injected value. The corollary is also true; if we drop the pulsar terms from the synthetic data and use the Earth terms equation for inference the optima is also correctly located. This evidences that it is the effect of dropping the pulsar terms from the measurement equation which causes this bias in the inferred posteriors. Similar results are observed for the other parameters which exhibit a bias in the nested sampling inference. \newline 

Why does dropping the pulsar terms bias these parameters in particular, whilst leaving others unaffected? For instance, why is the bias induced in $\iota$ so strong, whereas $\psi$ shows only a weak bias and  $\Omega$ shows no bias at all? When we generate synthetic data including the pulsar term, the state frequency of an individual pulsar $f_{\rm p}$ is effective modulated by the interference of two equal-amplitude, phase shifted waves (c.f. Equation \ref{eq:measurement}). Explicitly, we have the ``Earth-terms wave with a general form $y_{\rm Earth} = A \cos \xi$ for amplitude $A$ and phase $\xi$ and the ``pulsar-terms wave" with a general form $y_{\rm pulsar} = A \cos (\xi + \kappa)$ for phase offset $\kappa$. The net interference wave that modulates $f_{\rm p}$ is 
\begin{eqnarray}
	y_{\rm Earth} - y_{\rm pulsar} = 2 A \sin \left(\frac{\kappa}{2}\right) \sin \left(\xi + \frac{\kappa}{2}\right) \ .
\end{eqnarray}
The additional modulations from $y_{\rm pulsar}$ influence the amplitude of the resulting interference wave, but do not affect its frequency. When we model this data using the Kalman filter without the pulsar terms, the additional amplitude modulations from $y_{\rm pulsar}$ must be described by the single wave model, $y_{\rm Earth}$. As a result the $y_{\rm Earth}$ model must try to compensate for these amplitude modulations by adjusting the parameters which govern the amplitude of the single wave. Consequently the parameters which are most affected are those which determine the amplitude of the GW. Terms which influence the amplitude strongly such as $h_0$ and $\iota$ are strongly affected and exhibit a strong bias. Terms which influence the amplitude weakly such as $\psi$ exhibit a weaker bias. The wave amplitude is independent of the frequency and so $\Omega$ exhibits no bias.Since a shift in phase affects the instantaneous amplitude of the wave, $\Phi_0$ also exhibits a small bias, despite $A$ not being a function of $\Phi_0$. This hierarchy of biases for each parameter is also what we observe in Figure \ref{fig:parameter_space}, where $\alpha$ and $\delta$ are strongly over-constrained whilst $\Omega$ is well-estimated. \newline  

In order to ascertain how important the bias is for PTA continuous wave searches requires a thorough exploration of the astrophysical parameter space which we do not carry out in this work. The magnitude of the bias will vary for different points in the parameter space, as well as for different PTA configurations. If the bias is sufficiently modest then for quiet continuous wave sources with low SNR the uncertainty in the one-dimensional marginalised posterior may dominate and the bias may not be important for searches. Conversely if the bias is sufficiently strong, or the source sufficiently loud with low uncertainties then the bias may come to systematically affect the inferred parameters. \newline  

We have shown in this section how the dropping of the pulsar terms results in a bias in the inferred parameters, not just in the sky localisation parameters  \citep[e.g.][]{Zhupulsarterms,Chen2022} but additionally all parameters which influence the wave amplitude. Whilst the bias is generally small and does not prevent the recovery of accurate posteriors for our example system, it is present and may need to be accounted for for analysis in other parts of the parameter space. This bias is not particular to our method but a shared feature across likelihood based methods that do not include the pulsar terms in the inference model. The inclusion of the pulsar terms in the methods presented in this work in order to alleviate the bias will be a key goal of a future work. 



\section{Discussion}
We have shown how our complementary approach to PTA data analysis using a Kalman filter can successfully recover the underlying parameters of the model and calculate Bayes factors in order to perform Bayesian model selection. There are a number of potential extensions of this work which we now discuss.  \newline 

The natural first extension is to implement the method whilst retaining the pulsar terms of Equation \ref{eq:measurement}. Whilst PTA searches commonly drop the pulsar terms as standard practice, we have shown that this leads to biases in the inferred one-dimensional marginalized posteriors for the model parameters. Biases in sky localisation for synthetic datasets as a result of dropping the pulsar terms are also observed by \cite{Zhupulsarterms} and \cite{Chen2022}. Alternatively, if the method continues to be used with solely the Earth terms then it would be highly desirable to make systematic, quantitative estimates of the incurred biases in the model parameters across an astrophysically representative parameter space. \newline 

We have considered only a specific configuration of pulsars composing our synthetic PTA - the same pulsars that make up NANOGrav (Section \ref{sec:synt_pta}). Whilst our method is generally independent of the specific choice of pulsars, it would be of interest to compare the performance of the method using different pulsars configurations and different PTAs such as PPTA and the EPTA. Indeed, since adding pulsars to PTAs increases the computational demands of the data analysis it may be advantageous to optimally select a subset of the total available pulsars which may be able to provide comparable performance to a larger PTA  \citep{2023MNRAS.518.1802S}.  \newline 

Throughout this work we have assumed that all pulsars are observed at the same time, with a constant time sampling. In practice this assumption does not hold and different pulsars will be observed with different cadences at different times. Extending this method to non-constant time sampling is straightforward and the performance of the method should be evaluated in this regime. \newline 

We have taken our GW source to be monochromatic, i.e. $\Omega$ is a fixed parameter with no time dependence. Whilst this is an astronomically well-justified assumption (see discussion in Section \ref{sec:plane_gw}), and appropriate for this initial methods work, it would also be of interest to extend the state-space construction to enable the GW frequency to evolve in time. The GW source is monochromatic over the decadal PTA observation period, but the timescale set by the Earth-pulsar distance is comparable to the SMBHB evolution timescale \citep{Sesana2010}. For $\Delta f_{\rm gw} < 1 / T_{\rm obs}$ (see Equation \eqref{eq:f_evolution}) the GW source frequency evolution manifests as an incoherent source of noise in the pulsar terms, whilst for  $\Delta f_{\rm gw} > 1 / T_{\rm obs}$ the pulsar terms can affect the phase coherency of the Earth terms \citep{Perrodin2018}. Careful consideration of the evolution of the GW frequency will be important as we look to extend our method to include the pulsar terms in the inference model. \newline 


We have also assumed that there is only a single GW source that influences the received pulsar frequencies. However, it may be possible to resolve multiple continuous GW sources concurrently \citep{PhysRevD.85.044034}. Our method naturally extends to detecting multiple GW sources simultaneously; Equation \eqref{eq:measurement} is straightforwardly modified to become a linear superposition of multiple GWs. The stochastic background itself is the incoherent summation of many individual GW sources. It therefore stands to reason that it may be possible to extend this method to also search for a stochastic GW background, providing a complementary approach to detect the stochastic background without requiring a cross-correlation of the pulsar residuals to uncover the Hellings-Downs curve. \newline 


\textcolor{red}{TK: Lets also pre-empt reviewer and make it explicit why we are using frequencies rather than TOAs. Need to chat with group to get this clear in my head.}


%https://arxiv.org/pdf/2107.03047.pdf
\section{Conclusion}
In this paper we demonstrate a new method for the detection and parameter estimation of GWs from individual, monochromatic SMBHBs. We track the evolution of the intrinsic pulsar timing noise explicitly via a state-space method, rather than subtracting the ensemble-averaged statistics. That is, we disentangle statistically the specific time-ordered realisation of the timing noise from the GW induced modulations. This enables the inference of GW parameters conditioned on the specific observed realisation of the noisy data. We introduce the Kalman filter in order to track the intrinsic state evolution of the pulsar and combine this with a Bayesian sampling framework to estimate the posterior distributions of each parameter of the system, as well as the associated evidence (marginalised likelihood) of the model. We test our method on synthetic data. We initially focus on a single, astrophysically representative, SMBHB GW source detected with the 12.5-year NANOGrav pulsars observed over a 10 year timespan. The parameters of the model are accurately recovered and the minimal detectable strain is estimated to be $h_0 \sim 4 \times 10^{-15}$ for $\iota=1.0$ rad. The method is then further tested over 1000 noise realisations. Consistent MAP estimates of the parameters across all noise realisations are obtained for the majority of parameters, whilst the structural weak-identifiability of $\iota$ and $h_0$ results in a larger variance in the MAP estimates between individual noise realisations for these parameters. Exploration of a broader parameter space via 200 randomly sampled parameter vectors highlights biases in some parameters as a result of dropping the pulsar terms from the inference model. The cause of these biases is discussed. The extension of this method to include the pulsar term is a key challenge for a future work.
 
\appendix
\newpage
\section{Kalman recursion equations} \label{sec:kalman}
The linear Kalman filter operate on temporally discrete, noisy measurements $\boldsymbol{Y}_k$ which are related to a set of unobservable discrete system states $\boldsymbol{X}_k$ via a linear transformation:
\begin{equation}
	\boldsymbol{Y}_k = \boldsymbol{H}_k \boldsymbol{X}_k + \boldsymbol{v}_k \label{eq:kalman1}
\end{equation}
where $\boldsymbol{H}_k$ is the measurement matrix or observation model, $\boldsymbol{v}_k$ is a zero-mean Gaussian measurement noise with covariance $\boldsymbol{R}_k$, and the subscript $k$ labels the time-step. The Kalman filter takes the underlying states to evolve according to
\begin{equation}
	\boldsymbol{X}_k = \boldsymbol{F}_k \boldsymbol{X}_{k-1} + \boldsymbol{G}_k \boldsymbol{u}_k + \boldsymbol{w}_k \label{eq:kalman2}
\end{equation}
where $\boldsymbol{F}$ is the system dynamics matrix, $\boldsymbol{G}$ the input or control matrix. and $\boldsymbol{w}_k$ is a zero-mean Gaussian process noise with covariance $\boldsymbol{Q}_k$. \newline 

The Kalman filter is a recursive estimator with two distinct stages; a ``predict" stage where the state at the current time-step is predicted based on the state at the previous time-step, and an ``update" stage where the predicted state estimate is refined based on the measurement at that time-step. The predict stage updates the estimate of the state $\hat{\boldsymbol{X}}_{k|k-1}$ and the associated covariance $\hat{\boldsymbol{P}}_{k|k-1}$where the subscript notation ${k|k-1}$ denotes an estimate at discrete step $k$, given measurements from step $k-1$ and earlier. The predict step proceeds as,
\begin{equation}
\hat{\boldsymbol{X}}_{k|k-1} =  \boldsymbol{F}_k \hat{\boldsymbol{X}}_{k-1|k-1} + \boldsymbol{G}_k \boldsymbol{u}_k
\end{equation}
\begin{equation}
	\hat{\boldsymbol{P}}_{k|k-1} =  \boldsymbol{F}_k \hat{\boldsymbol{P}}_{k-1|k-1} \boldsymbol{F}_k^\intercal + \boldsymbol{Q}_k 
\end{equation}
The update step then uses the measurement $\boldsymbol{Y}_k$ to update $\hat{\boldsymbol{X}}_{k|k}$  and $\hat{\boldsymbol{P}}_{k|k}$ as,
\begin{equation}
	\boldsymbol{\epsilon}_{k} = \boldsymbol{Y}_k - \boldsymbol{H}_k \hat{\boldsymbol{X}}_{k|k-1}
\end{equation} 
\begin{equation}
	\boldsymbol{S}_k = \boldsymbol{H}_k \hat{\boldsymbol{P}}_{k|k-1} \boldsymbol{H}_k^\intercal + \boldsymbol{R}_k
\end{equation}
\begin{equation}
	\boldsymbol{K}_k = \hat{\boldsymbol{P}}_{k|k-1} \boldsymbol{H}_k^\intercal \boldsymbol{S}_k^{-1} \label{eq:kalman gain}
\end{equation}
\begin{equation}
	\hat{\boldsymbol{X}}_{k|k} =\hat{\boldsymbol{X}}_{k|k-1} +\boldsymbol{K}_k  \boldsymbol{\epsilon}_{k}
\end{equation}
\begin{equation}
		\hat{\boldsymbol{P}}_{k|k} = \left( \boldsymbol{I} - \boldsymbol{K}_k \boldsymbol{H}_k \right) 	\hat{\boldsymbol{P}}_{k|k-1}
\end{equation}
Equation \ref{eq:kalman gain} defines the ``Kalman gain" $\boldsymbol{K}_k$ which yields the minimal mean square error in the measurement post fit residual, $\boldsymbol{Y}_k - \boldsymbol{H}_k \hat{\boldsymbol{X}}_{k|k}$. \newline 


We can map our state-space model described in Section \ref{sec:model} onto the Kalman filter structure of Equations  
\ref{eq:kalman1}, \ref{eq:kalman2} as follows. We identify $\boldsymbol{X}$ with a vector of length $N$ composed of the intrinsic pulsar frequency states, i.e $\boldsymbol{X} = \left(f_{\rm p}^{(1)}, f_{\rm p}^{(2)}, ..., f_{\rm p}^{(N)}\right)$. Similarly  $\boldsymbol{Y} = \left(f_{\rm m}^{(1)}, f_{\rm m}^{(2)}, ..., f_{\rm m}^{(N)} \right)$. The states evolve according the continuous dynamical equation
\begin{equation}
	d \boldsymbol{X} = \boldsymbol{A} \boldsymbol{X} dt + \boldsymbol{C}(t) dt + \boldsymbol{\Sigma} d \boldsymbol{B}(t) \label{eq:kalmn2}
\end{equation}
where $\boldsymbol{A} = \text{diag} \left(\gamma^{(1)}, \gamma^{(2)}, ..., \gamma^{(N)}\right)$ is the state matrix, $\boldsymbol{C} = \left(C^{(1)}, C^{(2)}, ..., C^{(N)}\right)$ the input or control matrix where $C^{(i)} =\gamma^{(i)} \left(f_{\rm em}^{(i)} (0) + \dot{f}_{\rm em}(0)^{(i)} t \right) +  \dot{f}_{\rm em}(0)^{(i)}$ and $d\boldsymbol{B}(t)$ denotes a Wiener process with covariance matrix $\boldsymbol{\Sigma} = \text{diag} \left(\sigma^{(1)}, \sigma^{(2)}, ..., \sigma^{(N)}\right)$. Equation \ref{eq:kalmn2} is a Langevin equation (equivalently an Ornstein-Uhlenbeck process) which has a general solution given by \citep{gardiner2009stochastic},
\begin{equation}
	\boldsymbol{X}(t) = e^{\boldsymbol{A} t} \boldsymbol{X}(0) + \int_0^t e^{\boldsymbol{A}(t-t')} \boldsymbol{C}(t') dt' + \int_0^t e^{\boldsymbol{A}(t-t')} \boldsymbol{\Sigma} d\boldsymbol{B}(t') \label{eq:gardenier}
\end{equation} 
From Equation \ref{eq:gardenier} we can construct the discrete, recursive solution for $\boldsymbol{X}(t_k) = \boldsymbol{X}_k$ as Equation \ref{eq:kalman2} where
\begin{equation}
\boldsymbol{F}_k = e^{\boldsymbol{A}\left( t_{k+1} - t_k \right)} 
\end{equation}
\begin{equation}
	\boldsymbol{G}_k = \int_{t_i}^{t_{i+1}}  e^{\boldsymbol{A}\left( t_{k+1} - t' \right)}  \boldsymbol{C}(t') dt' 
\end{equation}
\begin{equation}
	\boldsymbol{w}_k = \int_{t_k}^{t_{k+1}} e^{\boldsymbol{A}\left( t_{k+1} - t' \right)} \boldsymbol{\Sigma} d \boldsymbol{B}(t')
	\end{equation}
For our system, the state, control and process noise covariance matrices then take the form:
\begin{equation}
	\boldsymbol{F}_k = 	\text{diag}\left(e^{- \gamma^{(1)} \Delta t},e^{- \gamma^{(2)} \Delta t},...,e^{- \gamma^{(N)} \Delta t} \right)
\end{equation}
\begin{equation}
\boldsymbol{G}_k	= \left(G^{(1)}_k, G^{(2)}_k,...,G^{(N)}_k \right)
\end{equation}
where
\begin{equation}
	G_k^{(n)} =    f^{(n)}_{\rm em}(t_1) + \dot{f}^{(n)}_{\rm em}(t_1)  \left[\Delta t + t_k \right] - e^{-\gamma \Delta t} \left[  f^{(n)}_{\rm em}(t_1) +\dot{f}^{(n)}_{\rm em}(t_1)  t_k \right]
\end{equation}
and
\begin{equation}
	\boldsymbol{Q}_k \boldsymbol{\delta}_{kj}= \langle \boldsymbol{\eta}_k \boldsymbol{\eta}_j^\intercal \rangle = \text{diag} \left(Q^{(1), Q^{(2)}},...,Q^{(N)}\right) 
\end{equation}
for 
\begin{equation}
	Q^{(n)} = \frac{- [\sigma^{n}]^2}{2 \gamma^{(n)}} \left( e^{-2 \gamma^{(n)} \Delta t} -1\right)
\end{equation}
where $\Delta t$ is the constant time sampling interval $=t_{k+1} -t_{k}$. \newline 


The remaining component matrices of the Kalman filter are the measurement matrix $\boldsymbol{H}_k$ and the measurement covariance matrix $\boldsymbol{R}_k$. These are defined straightforwardly from Equation \ref{eq:measurement}. Specifically, 
$\boldsymbol{H}_k$ is a diagonal matrix where the $n$-th component of the diagonal is given by $g^{(n)}(t_k)$ from Equation \ref{eq:g_func}. $\boldsymbol{R}_k = E \left[ \boldsymbol{v} \boldsymbol{v}^\intercal \right] = \sigma^2_{\rm m}$.













\section{Appendix on identifiability}\label{appendix_identifiability}


\textcolor{red}{TK TBD}



This paper is useful: \citep{KARLSSON2012941} \citep{SEDOGLAVIC2002735}





\section{Wasserstein distance}\label{sec:wasserstein}



It is well-known \cite{Dudley} that the Wasserstein distance suffers from the curse of dimensionality for dimensions $d \geq 3$:
\begin{eqnarray}
	\boldsymbol{E} [W_1(\mu_n,\mu)] \asymp n^{-\frac{1}{d}}
\end{eqnarray}
To sidestep this issue, we marginalize onto the distributions spanned by the individual gridpoints and take the WD between these 1-dimensional distributions. Such an approach is also adopted in \cite{Paxton2021,Vissio2020}. 





In order to compare the control and competitor ensemble probability distributions we adopt as our key metric the Wasserstein distance (WD). The WD intuitively defines a distance between two distributions as the optimal cost, with respect to some cost function $c(x,y)$,  of transporting a probability mass from position $x$ to position $y$. The $p$-Wasserstein distance between two distributions $\mu, \nu$ is
\begin{eqnarray}
	W_p(\mu,\nu)= \left( \inf_{\gamma \in \Gamma(\mu, \nu)}  \int c(x,y)^p d \gamma (x,y)\right)^{1/p}
\end{eqnarray}
where $\gamma(x,y)$ is the transport plan, $\Gamma(\mu, \nu)$ is the set of all couplings of $\mu$ and $\nu$ and $c(x,y)$ is the cost function. It is well-known \cite{Dudley} that the Wasserstein distance suffers from the curse of dimensionality for dimensions $d \geq 3$:
\begin{eqnarray}
	\boldsymbol{E} [W_1(\mu_n,\mu)] \asymp n^{-\frac{1}{d}}
\end{eqnarray}
To sidestep this issue, we marginalize onto the distributions spanned by the individual gridpoints and take the WD between these 1-dimensional distributions. Such an approach is also adopted in \cite{Paxton2021,Vissio2020}. We also take $p=1$ and $c(x,y) = |x-y|$ such that the WD values quoted in this work are given by
\begin{eqnarray}
	W_1(\mu,\nu)=  \inf_{\gamma \in \Gamma(\mu, \nu)} \int |x-y| d \gamma (x,y)
\end{eqnarray}
From the perspective of climate modelling, the WD has a nice physical interpretation given by the Monge-Kantorovich duality:
\begin{eqnarray}
	| \boldsymbol{E}(X_{\mu} )-\boldsymbol{E}(Y_{\nu} ) | \leq W_1(\mu, \nu) \label{eq:WDdefn}
\end{eqnarray}
i.e. the difference in the expected value of some random variable between two distributions is no bigger than the WD value itself. More explicitly, if the WD for surface temperature between two distributions is 1K, then this tells us that the difference in the expected temperature between the distributions is no greater than 1K. For a full review of the Wasserstein distance, including favourable properties and comparison with other metrics we refer the reader to the Appendix of Pax21.

%\section{References}
%\label{sec:ref_list}





\bibliographystyle{mnras}
\bibliography{example} % if your bibtex file is called example.bib




%%%%%%%%%%%%%%%%Scratch space

%Taking a tangible example, for pulsar J0023+0923 ATNF returns a frequency $f_{\rm em}^{(n)} (t_1) \sim 327.8$ Hz with an error $\epsilon \sim 4 \times 10^{13}$ Hz. 	The prior on $f_{\rm em}^{(n)} (t_1) \sim 327.8$ for this pulsar is then Uniform$(327.8 - 4 \times 10^{10},327.8 + 4 \times 10^{10} )$


%Alternatively, one can consider instead the alternative parametrisation in terms of $h_{+}$ and $h_{\times}$. 
%
%from Equation \ref{eq:hij} the amplitude of the plane GW perturbation at a particular sky location $\boldsymbol{n}$ is a linear combination of $h_{+}$ and $h_{\times}$. 
%
%
%
%Considering a single pulsar where the only unknown parameters of the model are $h_{+}$ and $h_{\times}$, the system is clearly under-determined - we have one equation with two unknowns - and the parameters are not identifiable 
%
%



%
%
%
%
%For instance, in Figure \ref{fig:omega_likelihood} we pass different values of $\Omega$ in the range $10^{-9}$ to $10^{-5}$ Hz into the Kalman filter, whilst holding the remaining parameters constant, and plot the retuned log-likelihood as a function of $\Omega$. 
%












%
%The second is that the log-likelihood curves for $\Omega, \delta$ and $\alpha$ are much more noisy than in the Earth-terms case. Whilst clear optima exist above the noise, and whilst local to the true value the curve becomes much more smooth, this noise presents an additional challenge to typical likelihood inference techniques which perform best on smooth likelihoods with a single clear global optima. It affects these parameters in particular since Equation \eqref{eq:g_func_trig} contains a phase term $\Omega \left(1 + \boldsymbol{n}\cdot \boldsymbol{q}^{(n)} \right)  d^{(n)}$, which is essentially a combination of these 3 parameters ($ \boldsymbol{n}$ is defined by $\delta$ and $\alpha$). When calculating a likelihood we are asking "How likely is this data, given these parameters". The inclusion of the pulsar terms results in effectively 2 continuous waves with different frequencies and phase. Perturbing e.g. $\alpha$ influences wave 1 in some non-liner way and wave 2 in some different non linear way. Whether this new set of parameters makes the data more likely depends on the particular combination of those two waves. \textcolor{red}{TK: this explanation of why these parameters is clunky because it is not properly clear to myself. Think in terms of $g(\theta)$ and $g(\hat{\theta})$}. 






%
%. In turn, each posterior distribution has a median value. We plot the distribution of these medians over the 1000 noise realisations for each parameter of $\boldsymbol{\theta}_{\rm gw}$ in Figure \ref{fig:median_distriubutins}. For each of these distributions we can also calculate the median value (i.e. the median of the medians) and compare it with the true injection value. This is shown by the red and orange dashed lines respectively in the Figure. Analogous to the results we saw in Figure \ref{fig:corner_plot_2}, the distributions of the median values of the parameters $\Omega, \Phi_0, \psi, \delta$ and $\alpha$ are very narrow, with a generally small discrepancy between the inferred value and the injected value. Conversely, the distributions for $\iota$ and $h_0$ are much broader and exhibit a bias of $\sim 0.18$ radians and $0.17 \times 10^{-12}$ respectively. This agrees with the results we discussed for the 9 noise realisations in Figure \ref{fig:corner_plot_2} where a bias in $\iota$ and $h_0$ was also observed. In addition to  $\iota$ and $h_0$  exhibiting a strong bias, the parameters $\psi$ and $\alpha$ also exhibit a small bias of magnitude $\sim 0.1$ and $\sim 0.04$ radians respectively. This bias is again a result of dropping the pulsar terms from the measurement equation and will be discussed in . 












%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Don't change these lines
\bsp	% typesetting comment
\label{lastpage}
\end{document}

% End of mnras_guide.tex
